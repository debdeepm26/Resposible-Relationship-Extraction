{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8661d4c5-bab5-4cbe-8d26-fbd950ad3e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import difflib as df\n",
    "import spacy\n",
    "import glob\n",
    "from spacy.util import compile_infix_regex\n",
    "from spacy.tokenizer import Tokenizer\n",
    "# from allennlp.predictors.predictor import Predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f33b9dbe-1a57-4865-ae6e-7ceaa547430b",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')\n",
    "# model_url = \"https://storage.googleapis.com/allennlp-public-models/coref-spanbert-large-2020.02.27.tar.gz\"\n",
    "# predictor = Predictor.from_path(model_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db46b407-b88a-430b-b53a-456fe0cfb04f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def custom_tokenizer(nlp):\n",
    "#     inf = list(nlp.Defaults.infixes)             \n",
    "#     inf[6] = inf[6].replace(\"0-9\", \"\")    \n",
    "#     inf = tuple(inf)                               \n",
    "#     infix_re = compile_infix_regex(inf)\n",
    "\n",
    "#     return Tokenizer(nlp.vocab, prefix_search=nlp.tokenizer.prefix_search,\n",
    "#                                 suffix_search=nlp.tokenizer.suffix_search,\n",
    "#                                 infix_finditer=infix_re.finditer,\n",
    "#                                 token_match=nlp.tokenizer.token_match,\n",
    "#                                 rules=nlp.Defaults.tokenizer_exceptions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "018c1bee-fc52-43d7-8be2-76406e37e3c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nlp.tokenizer = custom_tokenizer(nlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea7baf8-6471-41c5-b8a5-c480bec94619",
   "metadata": {},
   "source": [
    "# Read Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d0743f2-a42e-415c-a9f5-98d8c78ac072",
   "metadata": {},
   "outputs": [],
   "source": [
    "ACE2004_54_truth = pd.read_csv(\"../Data/relex_processed_data/relex/ACE2004/ground_truth/20000715_AFP_ARB.0054.eng.csv\", sep = \"\\t\")\n",
    "ACE2004_54_tagged = pd.read_csv(\"../Data/relex_processed_data/relex/ACE2004/tagged_tokens/20000715_AFP_ARB.0054.eng.csv\", sep = \"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44414148-aeab-4b38-913c-d6649196f98a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ACE2004_54_text = open(\"../Data/relex_processed_data/relex/ACE2004/raw_text/20000715_AFP_ARB.0054.eng.txt\", \"r\", encoding=\"utf8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9eca7759-b5b6-45dc-9ef0-1125f1c96ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "ACE2004_54_text_list = ACE2004_54_text.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "71c9da96-8cf0-40cb-be44-2275dd55167a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaning raw text file\n",
    "ACE2004_54_text_list = [sentence for sentence in ACE2004_54_text_list if sentence != '\\n']\n",
    "ACE2004_54_text_list = [sentence.replace(' \\n', '') for sentence in ACE2004_54_text_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d50e237d-3c09-42ff-8e26-87b23c55e360",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Harare 7-15 (AFP)-',\n",
       " \"Zimbabwe's President Robert Mugabe announced to journalists this evening Saturday that he had formed a new government, following legislative elections last June, with no opposition members included.\",\n",
       " 'The government, which was formed following legislative elections held last month and which the ruling party won by a slim majority, includes 19 ministers all of whom are members of the Zimbabwe African National Union - Patriotic Front.',\n",
       " 'The new government consists of 17 ministers and 2 undersecretaries.',\n",
       " 'The list, announced by President Mugabe at a press conference, reveals that the new government includes 10 new ministers selected from public figures and given ministerial posts for the first time, including a young minister named Simba Makoni appointed as head of the Ministry of Finance and Economic Development under circumstances where the country is witnessing an unprecedented economic crisis.',\n",
       " 'Elsewhere, Stan Modinge retains his appointment as Foreign Minister and Moven Mahashi as Defense.',\n",
       " \"In the recent legislative elections, the run-up to which was marked by violence, the ruling party won 62 out of the 150 parliamentary seats, in addition to the thirty seats whose incumbents are appointed by the country's president.\",\n",
       " 'The opposition won 58 seats, 57 of which were taken by the Movement for Democratic Change, the largest opposition party.']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ACE2004_54_text_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c8e62f8e-43eb-4508-aab3-19d1f352fef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_tagged_dict(tagged_token):\n",
    "#     tagged_dict = {} # creating a data dict using the tagged dataframe\n",
    "#     sent_count = 0\n",
    "#     word_count = 0\n",
    "#     error_flag = 0\n",
    "#     for index, row in tagged_token.iterrows():\n",
    "        \n",
    "#         if row[\"text\"] == \"'\":\n",
    "#             error_flag += 1\n",
    "#             if error_flag < 2:\n",
    "#                 key = str(sent_count) + \"_\" + str(word_count)+ \"_\"  + str(row[\"text\"])\n",
    "#                 tagged_dict[key] = [row[\"pos\"], row[\"tag\"], row[\"dep\"], row[\"entity type\"]]\n",
    "#                 word_count += 1\n",
    "#                 if row[\"pos\"] == \"SPACE\":\n",
    "#                     sent_count += 1\n",
    "#                     word_count = 0\n",
    "            \n",
    "#         elif row[\"text\"] != \"'\":\n",
    "#             error_flag = 0\n",
    "#             key = str(sent_count) + \"_\" + str(word_count)+ \"_\"  + str(row[\"text\"])\n",
    "#             tagged_dict[key] = [row[\"pos\"], row[\"tag\"], row[\"dep\"], row[\"entity type\"]]\n",
    "#             word_count += 1\n",
    "#             if row[\"pos\"] == \"SPACE\":\n",
    "#                 sent_count += 1\n",
    "#                 word_count = 0\n",
    "            \n",
    "#     return tagged_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5ba82dd7-6074-4da0-b707-886a5c982efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tagged_dict(tagged_token):\n",
    "    tagged_dict = {} # creating a data dict using the tagged dataframe\n",
    "    sent_count = 0\n",
    "    word_count = 0\n",
    "    error_flag = 0\n",
    "    for index, row in tagged_token.iterrows():\n",
    "        \n",
    "        key = str(sent_count) + \"_\" + str(word_count)\n",
    "        tagged_dict[key] = [row[\"pos\"], row[\"tag\"], row[\"dep\"], row[\"entity type\"], row[\"entity mention ID\"], str(row[\"text\"])]\n",
    "        word_count += 1\n",
    "        if row[\"pos\"] == \"SPACE\":\n",
    "            sent_count += 1\n",
    "            word_count = 0\n",
    "            \n",
    "    return tagged_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ac378f71-794f-41b9-9d66-374df4757f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged_dict = create_tagged_dict(ACE2004_54_tagged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "81d06a55-20b0-43bf-89a2-c32880e3d208",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0_0': ['PROPN', 'NNP', 'nmod', 'GPE', '19-1', 'Harare'],\n",
       " '0_1': ['NUM', 'CD', 'nummod', nan, nan, '7'],\n",
       " '0_2': ['SYM', 'SYM', 'punct', nan, nan, '-'],\n",
       " '0_3': ['NUM', 'CD', 'prep', nan, nan, '15'],\n",
       " '0_4': ['PUNCT', '-LRB-', 'punct', nan, nan, '('],\n",
       " '0_5': ['PROPN', 'NNP', 'intj', 'ORG', '20-29', 'AFP)-'],\n",
       " '0_6': ['SPACE', '_SP', nan, nan, nan, ' '],\n",
       " '1_0': ['PROPN', 'NNP', 'poss', 'GPE', '21-30', 'Zimbabwe'],\n",
       " '1_1': ['PART', 'POS', 'case', nan, nan, \"'s\"],\n",
       " '1_2': ['PROPN', 'NNP', 'compound', 'PER', '22-34', 'President'],\n",
       " '1_3': ['PROPN', 'NNP', 'compound', 'PER', '22-35', 'Robert'],\n",
       " '1_4': ['PROPN', 'NNP', 'nsubj', 'PER', '22-35', 'Mugabe'],\n",
       " '1_5': ['VERB', 'VBD', 'ROOT', nan, nan, 'announced'],\n",
       " '1_6': ['ADP', 'IN', 'prep', nan, nan, 'to'],\n",
       " '1_7': ['NOUN', 'NNS', 'pobj', 'PER', '25-39', 'journalists'],\n",
       " '1_8': ['DET', 'DT', 'det', nan, nan, 'this'],\n",
       " '1_9': ['NOUN', 'NN', 'npadvmod', nan, nan, 'evening'],\n",
       " '1_10': ['PROPN', 'NNP', 'npadvmod', nan, nan, 'Saturday'],\n",
       " '1_11': ['ADP', 'IN', 'mark', nan, nan, 'that'],\n",
       " '1_12': ['PRON', 'PRP', 'nsubj', 'PER', '22-36', 'he'],\n",
       " '1_13': ['VERB', 'VBD', 'aux', nan, nan, 'had'],\n",
       " '1_14': ['VERB', 'VBN', 'ccomp', nan, nan, 'formed'],\n",
       " '1_15': ['DET', 'DT', 'det', nan, nan, 'a'],\n",
       " '1_16': ['ADJ', 'JJ', 'amod', nan, nan, 'new'],\n",
       " '1_17': ['NOUN', 'NN', 'dobj', 'ORG', '26-40', 'government'],\n",
       " '1_18': ['PUNCT', ',', 'punct', nan, nan, ','],\n",
       " '1_19': ['VERB', 'VBG', 'advcl', nan, nan, 'following'],\n",
       " '1_20': ['ADJ', 'JJ', 'amod', nan, nan, 'legislative'],\n",
       " '1_21': ['NOUN', 'NNS', 'pobj', nan, nan, 'elections'],\n",
       " '1_22': ['ADJ', 'JJ', 'amod', nan, nan, 'last'],\n",
       " '1_23': ['PROPN', 'NNP', 'npadvmod', nan, nan, 'June'],\n",
       " '1_24': ['PUNCT', ',', 'punct', nan, nan, ','],\n",
       " '1_25': ['ADP', 'IN', 'mark', nan, nan, 'with'],\n",
       " '1_26': ['DET', 'DT', 'det', nan, nan, 'no'],\n",
       " '1_27': ['NOUN', 'NN', 'compound', nan, nan, 'opposition'],\n",
       " '1_28': ['NOUN', 'NNS', 'nsubj', 'PER', '27-41', 'members'],\n",
       " '1_29': ['VERB', 'VBD', 'advcl', nan, nan, 'included'],\n",
       " '1_30': ['PUNCT', '.', 'punct', nan, nan, '.'],\n",
       " '1_31': ['SPACE', '_SP', nan, nan, nan, '  '],\n",
       " '2_0': ['DET', 'DT', 'det', nan, nan, 'The'],\n",
       " '2_1': ['NOUN', 'NN', 'nsubj', 'ORG', '26-42', 'government'],\n",
       " '2_2': ['PUNCT', ',', 'punct', nan, nan, ','],\n",
       " '2_3': ['DET', 'WDT', 'nsubjpass', 'ORG', '26-43', 'which'],\n",
       " '2_4': ['VERB', 'VBD', 'auxpass', nan, nan, 'was'],\n",
       " '2_5': ['VERB', 'VBN', 'relcl', nan, nan, 'formed'],\n",
       " '2_6': ['VERB', 'VBG', 'prep', nan, nan, 'following'],\n",
       " '2_7': ['ADJ', 'JJ', 'amod', nan, nan, 'legislative'],\n",
       " '2_8': ['NOUN', 'NNS', 'pobj', nan, nan, 'elections'],\n",
       " '2_9': ['VERB', 'VBN', 'acl', nan, nan, 'held'],\n",
       " '2_10': ['ADJ', 'JJ', 'amod', nan, nan, 'last'],\n",
       " '2_11': ['NOUN', 'NN', 'npadvmod', nan, nan, 'month'],\n",
       " '2_12': ['CCONJ', 'CC', 'cc', nan, nan, 'and'],\n",
       " '2_13': ['DET', 'WDT', 'dobj', nan, nan, 'which'],\n",
       " '2_14': ['DET', 'DT', 'det', nan, nan, 'the'],\n",
       " '2_15': ['VERB', 'VBG', 'amod', nan, nan, 'ruling'],\n",
       " '2_16': ['NOUN', 'NN', 'nsubj', 'ORG', '28-44', 'party'],\n",
       " '2_17': ['VERB', 'VBD', 'conj', nan, nan, 'won'],\n",
       " '2_18': ['ADP', 'IN', 'agent', nan, nan, 'by'],\n",
       " '2_19': ['DET', 'DT', 'det', nan, nan, 'a'],\n",
       " '2_20': ['ADJ', 'JJ', 'amod', nan, nan, 'slim'],\n",
       " '2_21': ['NOUN', 'NN', 'pobj', nan, nan, 'majority'],\n",
       " '2_22': ['PUNCT', ',', 'punct', nan, nan, ','],\n",
       " '2_23': ['VERB', 'VBZ', 'ROOT', nan, nan, 'includes'],\n",
       " '2_24': ['NUM', 'CD', 'nummod', nan, nan, '19'],\n",
       " '2_25': ['NOUN', 'NNS', 'dobj', 'PER', '1-3', 'ministers'],\n",
       " '2_26': ['DET', 'DT', 'nsubj', 'PER', '1-4', 'all'],\n",
       " '2_27': ['ADP', 'IN', 'prep', nan, nan, 'of'],\n",
       " '2_28': ['PRON', 'WP', 'pobj', 'PER', '1-5', 'whom'],\n",
       " '2_29': ['VERB', 'VBP', 'relcl', nan, nan, 'are'],\n",
       " '2_30': ['NOUN', 'NNS', 'attr', 'PER', '1-6', 'members'],\n",
       " '2_31': ['ADP', 'IN', 'prep', nan, nan, 'of'],\n",
       " '2_32': ['DET', 'DT', 'det', nan, nan, 'the'],\n",
       " '2_33': ['PROPN', 'NNP', 'compound', 'ORG', '28-2', 'Zimbabwe'],\n",
       " '2_34': ['PROPN', 'NNP', 'compound', 'ORG', '28-2', 'African'],\n",
       " '2_35': ['PROPN', 'NNP', 'compound', 'ORG', '28-2', 'National'],\n",
       " '2_36': ['PROPN', 'NNP', 'compound', 'ORG', '28-2', 'Union'],\n",
       " '2_37': ['PUNCT', 'HYPH', 'punct', 'ORG', '28-2', '-'],\n",
       " '2_38': ['PROPN', 'NNP', 'compound', 'ORG', '28-2', 'Patriotic'],\n",
       " '2_39': ['PROPN', 'NNP', 'pobj', 'ORG', '28-2', 'Front'],\n",
       " '2_40': ['PUNCT', '.', 'punct', nan, nan, '.'],\n",
       " '2_41': ['SPACE', '_SP', nan, nan, nan, '  '],\n",
       " '3_0': ['DET', 'DT', 'det', nan, nan, 'The'],\n",
       " '3_1': ['ADJ', 'JJ', 'amod', nan, nan, 'new'],\n",
       " '3_2': ['NOUN', 'NN', 'nsubj', 'ORG', '26-7', 'government'],\n",
       " '3_3': ['VERB', 'VBZ', 'ROOT', nan, nan, 'consists'],\n",
       " '3_4': ['ADP', 'IN', 'prep', nan, nan, 'of'],\n",
       " '3_5': ['NUM', 'CD', 'nummod', nan, nan, '17'],\n",
       " '3_6': ['NOUN', 'NNS', 'pobj', 'PER', '3-8', 'ministers'],\n",
       " '3_7': ['CCONJ', 'CC', 'cc', nan, nan, 'and'],\n",
       " '3_8': ['NUM', 'CD', 'nummod', nan, nan, '2'],\n",
       " '3_9': ['NOUN', 'NNS', 'conj', 'PER', '4-9', 'undersecretaries'],\n",
       " '3_10': ['PUNCT', '.', 'punct', nan, nan, '.'],\n",
       " '3_11': ['SPACE', '_SP', nan, nan, nan, '  '],\n",
       " '4_0': ['DET', 'DT', 'det', nan, nan, 'The'],\n",
       " '4_1': ['NOUN', 'NN', 'nsubj', nan, nan, 'list'],\n",
       " '4_2': ['PUNCT', ',', 'punct', nan, nan, ','],\n",
       " '4_3': ['VERB', 'VBN', 'acl', nan, nan, 'announced'],\n",
       " '4_4': ['ADP', 'IN', 'agent', nan, nan, 'by'],\n",
       " '4_5': ['PROPN', 'NNP', 'compound', 'PER', '22-38', 'President'],\n",
       " '4_6': ['PROPN', 'NNP', 'pobj', 'PER', '22-37', 'Mugabe'],\n",
       " '4_7': ['ADP', 'IN', 'prep', nan, nan, 'at'],\n",
       " '4_8': ['DET', 'DT', 'det', nan, nan, 'a'],\n",
       " '4_9': ['NOUN', 'NN', 'compound', nan, nan, 'press'],\n",
       " '4_10': ['NOUN', 'NN', 'pobj', nan, nan, 'conference'],\n",
       " '4_11': ['PUNCT', ',', 'punct', nan, nan, ','],\n",
       " '4_12': ['VERB', 'VBZ', 'ROOT', nan, nan, 'reveals'],\n",
       " '4_13': ['ADP', 'IN', 'mark', nan, nan, 'that'],\n",
       " '4_14': ['DET', 'DT', 'det', nan, nan, 'the'],\n",
       " '4_15': ['ADJ', 'JJ', 'amod', nan, nan, 'new'],\n",
       " '4_16': ['NOUN', 'NN', 'nsubj', 'ORG', '26-10', 'government'],\n",
       " '4_17': ['VERB', 'VBZ', 'ccomp', nan, nan, 'includes'],\n",
       " '4_18': ['NUM', 'CD', 'nummod', nan, nan, '10'],\n",
       " '4_19': ['ADJ', 'JJ', 'amod', nan, nan, 'new'],\n",
       " '4_20': ['NOUN', 'NNS', 'dobj', 'PER', '5-11', 'ministers'],\n",
       " '4_21': ['VERB', 'VBN', 'acl', nan, nan, 'selected'],\n",
       " '4_22': ['ADP', 'IN', 'prep', nan, nan, 'from'],\n",
       " '4_23': ['ADJ', 'JJ', 'amod', nan, nan, 'public'],\n",
       " '4_24': ['NOUN', 'NNS', 'pobj', 'PER', '6-12', 'figures'],\n",
       " '4_25': ['CCONJ', 'CC', 'cc', nan, nan, 'and'],\n",
       " '4_26': ['VERB', 'VBN', 'conj', nan, nan, 'given'],\n",
       " '4_27': ['ADJ', 'JJ', 'amod', nan, nan, 'ministerial'],\n",
       " '4_28': ['NOUN', 'NNS', 'dobj', nan, nan, 'posts'],\n",
       " '4_29': ['ADP', 'IN', 'prep', nan, nan, 'for'],\n",
       " '4_30': ['DET', 'DT', 'det', nan, nan, 'the'],\n",
       " '4_31': ['ADJ', 'JJ', 'amod', nan, nan, 'first'],\n",
       " '4_32': ['NOUN', 'NN', 'pobj', nan, nan, 'time'],\n",
       " '4_33': ['PUNCT', ',', 'punct', nan, nan, ','],\n",
       " '4_34': ['VERB', 'VBG', 'prep', nan, nan, 'including'],\n",
       " '4_35': ['DET', 'DT', 'det', nan, nan, 'a'],\n",
       " '4_36': ['ADJ', 'JJ', 'amod', nan, nan, 'young'],\n",
       " '4_37': ['NOUN', 'NN', 'pobj', 'PER', '7-13', 'minister'],\n",
       " '4_38': ['VERB', 'VBN', 'acl', nan, nan, 'named'],\n",
       " '4_39': ['PROPN', 'NNP', 'compound', 'PER', '7-14', 'Simba'],\n",
       " '4_40': ['PROPN', 'NNP', 'oprd', 'PER', '7-14', 'Makoni'],\n",
       " '4_41': ['VERB', 'VBD', 'acl', nan, nan, 'appointed'],\n",
       " '4_42': ['ADP', 'IN', 'prep', nan, nan, 'as'],\n",
       " '4_43': ['NOUN', 'NN', 'pobj', 'PER', '7-15', 'head'],\n",
       " '4_44': ['ADP', 'IN', 'prep', nan, nan, 'of'],\n",
       " '4_45': ['DET', 'DT', 'det', nan, nan, 'the'],\n",
       " '4_46': ['PROPN', 'NNP', 'pobj', 'ORG', '9-16', 'Ministry'],\n",
       " '4_47': ['ADP', 'IN', 'prep', 'ORG', '9-16', 'of'],\n",
       " '4_48': ['PROPN', 'NNP', 'pobj', 'ORG', '9-16', 'Finance'],\n",
       " '4_49': ['CCONJ', 'CC', 'cc', 'ORG', '9-16', 'and'],\n",
       " '4_50': ['PROPN', 'NNP', 'compound', 'ORG', '9-16', 'Economic'],\n",
       " '4_51': ['PROPN', 'NNP', 'conj', 'ORG', '9-16', 'Development'],\n",
       " '4_52': ['ADP', 'IN', 'prep', nan, nan, 'under'],\n",
       " '4_53': ['NOUN', 'NNS', 'pobj', nan, nan, 'circumstances'],\n",
       " '4_54': ['ADV', 'WRB', 'advmod', nan, nan, 'where'],\n",
       " '4_55': ['DET', 'DT', 'det', nan, nan, 'the'],\n",
       " '4_56': ['NOUN', 'NN', 'nsubj', 'GPE', '21-31', 'country'],\n",
       " '4_57': ['VERB', 'VBZ', 'aux', nan, nan, 'is'],\n",
       " '4_58': ['VERB', 'VBG', 'relcl', nan, nan, 'witnessing'],\n",
       " '4_59': ['DET', 'DT', 'det', nan, nan, 'an'],\n",
       " '4_60': ['ADJ', 'JJ', 'amod', nan, nan, 'unprecedented'],\n",
       " '4_61': ['ADJ', 'JJ', 'amod', nan, nan, 'economic'],\n",
       " '4_62': ['NOUN', 'NN', 'dobj', nan, nan, 'crisis'],\n",
       " '4_63': ['PUNCT', '.', 'punct', nan, nan, '.'],\n",
       " '4_64': ['SPACE', '_SP', nan, nan, nan, '  '],\n",
       " '5_0': ['PROPN', 'NNP', 'advmod', nan, nan, 'Elsewhere'],\n",
       " '5_1': ['PUNCT', ',', 'punct', nan, nan, ','],\n",
       " '5_2': ['PROPN', 'NNP', 'compound', 'PER', '10-17', 'Stan'],\n",
       " '5_3': ['PROPN', 'NNP', 'nsubj', 'PER', '10-17', 'Modinge'],\n",
       " '5_4': ['VERB', 'VBZ', 'ROOT', nan, nan, 'retains'],\n",
       " '5_5': ['DET', 'PRP$', 'poss', 'PER', '10-18', 'his'],\n",
       " '5_6': ['NOUN', 'NN', 'dobj', nan, nan, 'appointment'],\n",
       " '5_7': ['ADP', 'IN', 'prep', nan, nan, 'as'],\n",
       " '5_8': ['PROPN', 'NNP', 'compound', nan, nan, 'Foreign'],\n",
       " '5_9': ['PROPN', 'NNP', 'pobj', 'PER', '10-19', 'Minister'],\n",
       " '5_10': ['CCONJ', 'CC', 'cc', nan, nan, 'and'],\n",
       " '5_11': ['PROPN', 'NNP', 'compound', 'PER', '12-21', 'Moven'],\n",
       " '5_12': ['PROPN', 'NNP', 'conj', 'PER', '12-21', 'Mahashi'],\n",
       " '5_13': ['ADP', 'IN', 'prep', nan, nan, 'as'],\n",
       " '5_14': ['PROPN', 'NNP', 'pobj', 'PER', '12-20', 'Defense'],\n",
       " '5_15': ['PUNCT', '.', 'punct', nan, nan, '.'],\n",
       " '5_16': ['SPACE', '_SP', nan, nan, nan, '  '],\n",
       " '6_0': ['ADP', 'IN', 'prep', nan, nan, 'In'],\n",
       " '6_1': ['DET', 'DT', 'det', nan, nan, 'the'],\n",
       " '6_2': ['ADJ', 'JJ', 'amod', nan, nan, 'recent'],\n",
       " '6_3': ['ADJ', 'JJ', 'amod', nan, nan, 'legislative'],\n",
       " '6_4': ['NOUN', 'NNS', 'pobj', nan, nan, 'elections'],\n",
       " '6_5': ['PUNCT', ',', 'punct', nan, nan, ','],\n",
       " '6_6': ['DET', 'DT', 'det', nan, nan, 'the'],\n",
       " '6_7': ['NOUN', 'NN', 'compound', nan, nan, 'run'],\n",
       " '6_8': ['PUNCT', 'HYPH', 'punct', nan, nan, '-'],\n",
       " '6_9': ['NOUN', 'NN', 'nsubjpass', nan, nan, 'up'],\n",
       " '6_10': ['PART', 'TO', 'prep', nan, nan, 'to'],\n",
       " '6_11': ['DET', 'WDT', 'pobj', nan, nan, 'which'],\n",
       " '6_12': ['VERB', 'VBD', 'auxpass', nan, nan, 'was'],\n",
       " '6_13': ['VERB', 'VBN', 'ccomp', nan, nan, 'marked'],\n",
       " '6_14': ['ADP', 'IN', 'agent', nan, nan, 'by'],\n",
       " '6_15': ['NOUN', 'NN', 'pobj', nan, nan, 'violence'],\n",
       " '6_16': ['PUNCT', ',', 'punct', nan, nan, ','],\n",
       " '6_17': ['DET', 'DT', 'det', nan, nan, 'the'],\n",
       " '6_18': ['VERB', 'VBG', 'amod', nan, nan, 'ruling'],\n",
       " '6_19': ['NOUN', 'NN', 'nsubj', 'ORG', '28-22', 'party'],\n",
       " '6_20': ['VERB', 'VBD', 'ROOT', nan, nan, 'won'],\n",
       " '6_21': ['NUM', 'CD', 'dobj', nan, nan, '62'],\n",
       " '6_22': ['ADP', 'IN', 'prep', nan, nan, 'out'],\n",
       " '6_23': ['ADP', 'IN', 'prep', nan, nan, 'of'],\n",
       " '6_24': ['DET', 'DT', 'det', nan, nan, 'the'],\n",
       " '6_25': ['NUM', 'CD', 'nummod', nan, nan, '150'],\n",
       " '6_26': ['ADJ', 'JJ', 'amod', nan, nan, 'parliamentary'],\n",
       " '6_27': ['NOUN', 'NNS', 'pobj', nan, nan, 'seats'],\n",
       " '6_28': ['PUNCT', ',', 'punct', nan, nan, ','],\n",
       " '6_29': ['ADP', 'IN', 'prep', nan, nan, 'in'],\n",
       " '6_30': ['NOUN', 'NN', 'pobj', nan, nan, 'addition'],\n",
       " '6_31': ['ADP', 'IN', 'prep', nan, nan, 'to'],\n",
       " '6_32': ['DET', 'DT', 'det', nan, nan, 'the'],\n",
       " '6_33': ['NUM', 'CD', 'nummod', nan, nan, 'thirty'],\n",
       " '6_34': ['NOUN', 'NNS', 'pobj', nan, nan, 'seats'],\n",
       " '6_35': ['DET', 'WP$', 'poss', nan, nan, 'whose'],\n",
       " '6_36': ['NOUN', 'NNS', 'nsubjpass', 'PER', '14-23', 'incumbents'],\n",
       " '6_37': ['VERB', 'VBP', 'auxpass', nan, nan, 'are'],\n",
       " '6_38': ['VERB', 'VBN', 'relcl', nan, nan, 'appointed'],\n",
       " '6_39': ['ADP', 'IN', 'agent', nan, nan, 'by'],\n",
       " '6_40': ['DET', 'DT', 'det', nan, nan, 'the'],\n",
       " '6_41': ['NOUN', 'NN', 'poss', 'GPE', '21-32', 'country'],\n",
       " '6_42': ['PART', 'POS', 'case', nan, nan, \"'s\"],\n",
       " '6_43': ['NOUN', 'NN', 'pobj', 'PER', '15-24', 'president'],\n",
       " '6_44': ['PUNCT', '.', 'punct', nan, nan, '.'],\n",
       " '6_45': ['SPACE', '_SP', nan, nan, nan, ' '],\n",
       " '7_0': ['DET', 'DT', 'det', nan, nan, 'The'],\n",
       " '7_1': ['NOUN', 'NN', 'nsubj', 'ORG', '16-25', 'opposition'],\n",
       " '7_2': ['VERB', 'VBD', 'ROOT', nan, nan, 'won'],\n",
       " '7_3': ['NUM', 'CD', 'nummod', nan, nan, '58'],\n",
       " '7_4': ['NOUN', 'NNS', 'dobj', nan, nan, 'seats'],\n",
       " '7_5': ['PUNCT', ',', 'punct', nan, nan, ','],\n",
       " '7_6': ['NUM', 'CD', 'nsubjpass', nan, nan, '57'],\n",
       " '7_7': ['ADP', 'IN', 'prep', nan, nan, 'of'],\n",
       " '7_8': ['DET', 'WDT', 'pobj', nan, nan, 'which'],\n",
       " '7_9': ['VERB', 'VBD', 'auxpass', nan, nan, 'were'],\n",
       " '7_10': ['VERB', 'VBN', 'relcl', nan, nan, 'taken'],\n",
       " '7_11': ['ADP', 'IN', 'agent', nan, nan, 'by'],\n",
       " '7_12': ['DET', 'DT', 'det', nan, nan, 'the'],\n",
       " '7_13': ['PROPN', 'NNP', 'pobj', 'ORG', '17-27', 'Movement'],\n",
       " '7_14': ['ADP', 'IN', 'prep', 'ORG', '17-27', 'for'],\n",
       " '7_15': ['PROPN', 'NNP', 'compound', 'ORG', '17-27', 'Democratic'],\n",
       " '7_16': ['PROPN', 'NNP', 'pobj', 'ORG', '17-27', 'Change'],\n",
       " '7_17': ['PUNCT', ',', 'punct', nan, nan, ','],\n",
       " '7_18': ['DET', 'DT', 'det', nan, nan, 'the'],\n",
       " '7_19': ['ADJ', 'JJS', 'amod', nan, nan, 'largest'],\n",
       " '7_20': ['NOUN', 'NN', 'compound', nan, nan, 'opposition'],\n",
       " '7_21': ['NOUN', 'NN', 'appos', 'ORG', '17-28', 'party'],\n",
       " '7_22': ['PUNCT', '.', 'punct', nan, nan, '.'],\n",
       " '7_23': ['SPACE', '_SP', nan, nan, nan, ' ']}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b37bd0-41d3-43b5-a34e-1374489bb069",
   "metadata": {},
   "source": [
    "# Sentence Entity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d48df2a7-7802-49ae-8c04-05ee43d75cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_entity(tagged_dict, sentence_index, sentence_nlp, enhanced_bool = False):\n",
    "    \n",
    "    entities = []\n",
    "    entity = \"\"\n",
    "    entity_index = \"\"\n",
    "    prev_token = \"\"\n",
    "    prev_token_index = \"\"\n",
    "    indices = []\n",
    "    entities_types = []\n",
    "    \n",
    "    \n",
    "    if enhanced_bool == True:\n",
    "        for index, token in enumerate(sentence_nlp):\n",
    "\n",
    "            if token.text == \"''\":\n",
    "                token_text = \"'\"\n",
    "            else:\n",
    "                token_text = token.text\n",
    "\n",
    "            key = str(sentence_index) + \"_\" + str(index)\n",
    "\n",
    "            pos = tagged_dict[key][0]\n",
    "            dep = str(tagged_dict[key][2])\n",
    "            entity_type = tagged_dict[key][3]\n",
    "\n",
    "            if not pd.isnull(entity_type):\n",
    "                entity = entity + \" \" + token_text\n",
    "                if entity_index != \"\":\n",
    "                    entity_index = entity_index + \"_\" + str(index)\n",
    "                else:\n",
    "                    entity_index = str(index)\n",
    "\n",
    "            elif pd.isnull(entity_type) and (dep == \"compound\" or dep.endswith(\"mod\")):\n",
    "                prev_token = prev_token + \" \" + token_text\n",
    "                if prev_token_index != \"\":\n",
    "                    prev_token_index = prev_token_index + \"_\" + str(index)\n",
    "                else:\n",
    "                    prev_token_index = str(index)\n",
    "\n",
    "            elif pd.isnull(entity_type) and dep != \"compound\" and dep.endswith(\"mod\") == False and entity == \"\":\n",
    "                prev_token = \"\"\n",
    "                prev_token_index = \"\"\n",
    "\n",
    "            entity = entity.strip()\n",
    "\n",
    "            if pd.isnull(entity_type) and entity != \"\":\n",
    "\n",
    "                if prev_token != \"\":\n",
    "                    entity = prev_token + \" \" + entity\n",
    "                    entity_index = prev_token_index + \"_\" + entity_index\n",
    "\n",
    "                entities.append(entity.strip())\n",
    "                indices.append(entity_index)\n",
    "                entities_types.append(entity_type.strip())\n",
    "                entity = \"\"\n",
    "                entity_index = \"\"\n",
    "                prev_token = \"\"\n",
    "                prev_token_index = \"\"\n",
    "    else:\n",
    "        for key in tagged_dict.keys():\n",
    "            \n",
    "            key_split = key.split(\"_\")\n",
    "            sentence_id = key_split[0]\n",
    "            key_id = key_split[1]\n",
    "            \n",
    "            if str(sentence_id) == str(sentence_index):\n",
    "                entity_type = tagged_dict[key][3]\n",
    "                entity_id = tagged_dict[key][4]\n",
    "                \n",
    "                if not pd.isnull(entity_type):\n",
    "                    \n",
    "                    if len(indices) != 0 and indices[-1][0] == entity_id:\n",
    "                        entities[-1] = entities[-1] + \" \" + tagged_dict[key][5]\n",
    "                        \n",
    "                    else:\n",
    "                        entities.append(tagged_dict[key][5])\n",
    "                        indices.append([entity_id, key_id])\n",
    "                        entities_types.append(entity_type.strip())\n",
    "                    \n",
    "    return entities, indices, entities_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "99a9628a-77d5-46a4-b44d-9d1fb41fe0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_root(tagged_dict, sentence_index, sentence_nlp):\n",
    "    \n",
    "    sent_roots = []\n",
    "    sent_roots_index = []\n",
    "    \n",
    "    for index, token in enumerate(sentence_nlp):\n",
    "        \n",
    "        if token.text == \"''\":\n",
    "            token_text = \"'\"\n",
    "        else:\n",
    "            token_text = token.text\n",
    "            \n",
    "        key = str(sentence_index) + \"_\" + str(index)\n",
    "        dep = tagged_dict[key][2]\n",
    "        \n",
    "        if dep == \"ROOT\":\n",
    "            sent_roots.append(token.text)\n",
    "            sent_roots_index.append(index)\n",
    "            \n",
    "    return sent_roots, sent_roots_index\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d2fa9689-fa29-4f1a-a1b4-87e9f4769869",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_sentences(entity_list):\n",
    "    \n",
    "    for index, sentence_entity in enumerate(entity_list):\n",
    "        if len(sentence_entity[2][0]) == 0:\n",
    "            entity_list.pop(index)\n",
    "            \n",
    "    return entity_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bbeb7485-0a5f-496c-8aa4-3e66814ee1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resolve_corefernce(sentence, sentence_nlp, entites, indices):\n",
    "    prediction = predictor.predict(document=sentence)\n",
    "    clusters = prediction['clusters']\n",
    "    \n",
    "    if (len(clusters)) != 0:\n",
    "        for cluster in clusters:\n",
    "            if cluster[1][0] == cluster[1][1]:\n",
    "                index = cluster[1][1]\n",
    "                if str(index) in indices:\n",
    "                    resolve_index = indices.index(str(index))\n",
    "                    resolution_index = cluster[0]\n",
    "                    entites[resolve_index] = sentence_nlp[resolution_index[0] : resolution_index[1] + 1].text\n",
    "            \n",
    "    return entites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f7a46774-00ff-448e-979a-98bc0773d7eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_entity_list = []\n",
    "\n",
    "for index, sentence in enumerate(ACE2004_54_text_list):\n",
    "    sentence_nlp = nlp(sentence)\n",
    "    entities, indices, entities_types = sentence_entity(tagged_dict, index, sentence_nlp, False)\n",
    "    # entities = resolve_corefernce(sentence, sentence_nlp, entities, indices) #resolving coreferences\n",
    "    # sent_roots, sent_roots_index = extract_root(tagged_dict, index, sentence_nlp)\n",
    "    sentences_entity_list.append([index, [entities, indices, entities_types]])\n",
    "    \n",
    "# sentences_entity_list = filter_sentences(sentences_entity_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8811ea4f-a305-4150-86f6-dcec4d540785",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Harare 7-15 (AFP)-\n",
      "[['Harare', 'AFP)-'], [['19-1', '0'], ['20-29', '5']], ['GPE', 'ORG']]\n",
      "\n",
      "\n",
      "1\n",
      "Zimbabwe's President Robert Mugabe announced to journalists this evening Saturday that he had formed a new government, following legislative elections last June, with no opposition members included.\n",
      "[['Zimbabwe', 'President', 'Robert Mugabe', 'journalists', 'he', 'government', 'members'], [['21-30', '0'], ['22-34', '2'], ['22-35', '3'], ['25-39', '7'], ['22-36', '12'], ['26-40', '17'], ['27-41', '28']], ['GPE', 'PER', 'PER', 'PER', 'PER', 'ORG', 'PER']]\n",
      "\n",
      "\n",
      "2\n",
      "The government, which was formed following legislative elections held last month and which the ruling party won by a slim majority, includes 19 ministers all of whom are members of the Zimbabwe African National Union - Patriotic Front.\n",
      "[['government', 'which', 'party', 'ministers', 'all', 'whom', 'members', 'Zimbabwe African National Union - Patriotic Front'], [['26-42', '1'], ['26-43', '3'], ['28-44', '16'], ['1-3', '25'], ['1-4', '26'], ['1-5', '28'], ['1-6', '30'], ['28-2', '33']], ['ORG', 'ORG', 'ORG', 'PER', 'PER', 'PER', 'PER', 'ORG']]\n",
      "\n",
      "\n",
      "3\n",
      "The new government consists of 17 ministers and 2 undersecretaries.\n",
      "[['government', 'ministers', 'undersecretaries'], [['26-7', '2'], ['3-8', '6'], ['4-9', '9']], ['ORG', 'PER', 'PER']]\n",
      "\n",
      "\n",
      "4\n",
      "The list, announced by President Mugabe at a press conference, reveals that the new government includes 10 new ministers selected from public figures and given ministerial posts for the first time, including a young minister named Simba Makoni appointed as head of the Ministry of Finance and Economic Development under circumstances where the country is witnessing an unprecedented economic crisis.\n",
      "[['President', 'Mugabe', 'government', 'ministers', 'figures', 'minister', 'Simba Makoni', 'head', 'Ministry of Finance and Economic Development', 'country'], [['22-38', '5'], ['22-37', '6'], ['26-10', '16'], ['5-11', '20'], ['6-12', '24'], ['7-13', '37'], ['7-14', '39'], ['7-15', '43'], ['9-16', '46'], ['21-31', '56']], ['PER', 'PER', 'ORG', 'PER', 'PER', 'PER', 'PER', 'PER', 'ORG', 'GPE']]\n",
      "\n",
      "\n",
      "5\n",
      "Elsewhere, Stan Modinge retains his appointment as Foreign Minister and Moven Mahashi as Defense.\n",
      "[['Stan Modinge', 'his', 'Minister', 'Moven Mahashi', 'Defense'], [['10-17', '2'], ['10-18', '5'], ['10-19', '9'], ['12-21', '11'], ['12-20', '14']], ['PER', 'PER', 'PER', 'PER', 'PER']]\n",
      "\n",
      "\n",
      "6\n",
      "In the recent legislative elections, the run-up to which was marked by violence, the ruling party won 62 out of the 150 parliamentary seats, in addition to the thirty seats whose incumbents are appointed by the country's president.\n",
      "[['party', 'incumbents', 'country', 'president'], [['28-22', '19'], ['14-23', '36'], ['21-32', '41'], ['15-24', '43']], ['ORG', 'PER', 'GPE', 'PER']]\n",
      "\n",
      "\n",
      "7\n",
      "The opposition won 58 seats, 57 of which were taken by the Movement for Democratic Change, the largest opposition party.\n",
      "[['opposition', 'Movement for Democratic Change', 'party'], [['16-25', '1'], ['17-27', '13'], ['17-28', '21']], ['ORG', 'ORG', 'ORG']]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for index, entity_list in enumerate(sentences_entity_list):\n",
    "    print(entity_list[0])\n",
    "    print(ACE2004_54_text_list[entity_list[0]])\n",
    "    print(entity_list[1])\n",
    "    # print(entity_list[2])\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f04ef9c3-4f12-4b0e-a996-c6107b4176a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_enhanced_relation(tagged_dict, sentence_index, entity_list, sentence):\n",
    "    \n",
    "    entities_relations = []\n",
    "    \n",
    "    sentence_entities = entity_list[1]\n",
    "    \n",
    "    sentence_nlp = nlp(sentence)\n",
    "    \n",
    "    entities_text = sentence_entities[0]\n",
    "    entities_text_indices = sentence_entities[1]\n",
    "    entities_len = len(entities_text)\n",
    "    \n",
    "    for index, entity_text in enumerate(entities_text):\n",
    "        \n",
    "        entity1 = \"\"\n",
    "        entity1_index = \"\"\n",
    "        entity2 = \"\"\n",
    "        entity2_index = \"\"\n",
    "        \n",
    "        entity_pair_relation = \"\"\n",
    "        entity_pair_relation_pos_pattern = \"\"\n",
    "        \n",
    "        if index == entities_len - 1:\n",
    "            continue\n",
    "        else:\n",
    "            \n",
    "            entity1 = entity_text\n",
    "            entity1_index = entities_indices[index][1]\n",
    "            entity1_id = entities_indices[index][0]\n",
    "            \n",
    "            entity2 = entities_text[index + 1]\n",
    "            entity2_index = entities_indices[index + 1][1]\n",
    "            entity2_id = entities_indices[index + 1][0]\n",
    "            \n",
    "            for i in range(int(entity1_index) + 1, int(entity2_index)):\n",
    "                \n",
    "                if sentence_nlp[i].text == \"''\":\n",
    "                    token_text = \"'\"\n",
    "                else:\n",
    "                    token_text = sentence_nlp[i].text\n",
    "                \n",
    "                entity_pair_relation = entity_pair_relation + \" \" + token_text\n",
    "                \n",
    "                if entity_pair_relation_pos_pattern != \"\":\n",
    "                    entity_pair_relation_pos_pattern = entity_pair_relation_pos_pattern + \"-\" + tagged_dict[str(sentence_index) + \"_\" + str(i)][0]\n",
    "                else:\n",
    "                    entity_pair_relation_pos_pattern = tagged_dict[str(sentence_index) + \"_\" + str(i)][0]\n",
    "                    \n",
    "        entity_pair_relation = entity1 + \" \" + entity_pair_relation.strip() + \" \" + entity2 \n",
    "        entities_relations.append([[entity1, entity2],[entity_pair_relation, entity_pair_relation_pos_pattern]])\n",
    "    \n",
    "    return entities_relations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "81c940d3-85ca-430f-8f16-251e6d643124",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_relation(tagged_dict, sentence_index, entity_list):\n",
    "    \n",
    "    entities_relations = []\n",
    "    \n",
    "    sentence_entities = entity_list[1]\n",
    "    \n",
    "    entities_text = sentence_entities[0]\n",
    "    entities_indices = sentence_entities[1]\n",
    "    entities_type = sentence_entities[2]\n",
    "    entities_len = len(entities_text)\n",
    "    \n",
    "    for index, entity_text in enumerate(entities_text):\n",
    "        \n",
    "        entity1 = \"\"\n",
    "        entity1_index = \"\"\n",
    "        entity2 = \"\"\n",
    "        entity2_index = \"\"\n",
    "        \n",
    "        entity_pair_relation = \"\"\n",
    "        entity_pair_relation_pos_pattern = \"\"\n",
    "        \n",
    "        if index == entities_len - 1:\n",
    "            continue\n",
    "        else:\n",
    "            \n",
    "            entity1 = entity_text\n",
    "            entity1_index = entities_indices[index][1]\n",
    "            entity1_id = entities_indices[index][0]\n",
    "            entity1_type = entities_type[index]\n",
    "            \n",
    "            entity2 = entities_text[index + 1]\n",
    "            entity2_index = entities_indices[index + 1][1]\n",
    "            entity2_id = entities_indices[index + 1][0]\n",
    "            entity2_type = entities_type[index + 1]\n",
    "            \n",
    "            for i in range(int(entity1_index) + 1, int(entity2_index)):\n",
    "                \n",
    "                token_text = tagged_dict[str(sentence_index) + \"_\" + str(i)][5]\n",
    "                \n",
    "                entity_pair_relation = entity_pair_relation + \" \" + token_text\n",
    "                \n",
    "                if entity_pair_relation_pos_pattern != \"\":\n",
    "                    entity_pair_relation_pos_pattern = entity_pair_relation_pos_pattern + \"-\" + tagged_dict[str(sentence_index) + \"_\" + str(i)][0]\n",
    "                else:\n",
    "                    entity_pair_relation_pos_pattern = tagged_dict[str(sentence_index) + \"_\" + str(i)][0]\n",
    "                    \n",
    "        entity_pair_relation = entity1 + \" \" + entity_pair_relation.strip() + \" \" + entity2\n",
    "        entity_pair_type = entity1_type + \"-\" + entity2_type\n",
    "        entities_relations.append([[entity1, entity2], [entity1_id, entity2_id, entity_pair_type], [entity_pair_relation, entity_pair_relation_pos_pattern]])\n",
    "    \n",
    "    return entities_relations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f9dd2a1f-c6ce-4b7c-92df-11c99ca60d21",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Harare 7-15 (AFP)-\n",
      "[['Harare', 'AFP)-'], [['19-1', '0'], ['20-29', '5']], ['GPE', 'ORG']]\n",
      "=====\n",
      "[['Harare', 'AFP)-'], ['19-1', '20-29', 'GPE-ORG'], ['Harare 7 - 15 ( AFP)-', 'NUM-SYM-NUM-PUNCT']]\n",
      "=====\n",
      "\n",
      "\n",
      "Zimbabwe's President Robert Mugabe announced to journalists this evening Saturday that he had formed a new government, following legislative elections last June, with no opposition members included.\n",
      "[['Zimbabwe', 'President', 'Robert Mugabe', 'journalists', 'he', 'government', 'members'], [['21-30', '0'], ['22-34', '2'], ['22-35', '3'], ['25-39', '7'], ['22-36', '12'], ['26-40', '17'], ['27-41', '28']], ['GPE', 'PER', 'PER', 'PER', 'PER', 'ORG', 'PER']]\n",
      "=====\n",
      "[['Zimbabwe', 'President'], ['21-30', '22-34', 'GPE-PER'], [\"Zimbabwe 's President\", 'PART']]\n",
      "[['President', 'Robert Mugabe'], ['22-34', '22-35', 'PER-PER'], ['President  Robert Mugabe', '']]\n",
      "[['Robert Mugabe', 'journalists'], ['22-35', '25-39', 'PER-PER'], ['Robert Mugabe Mugabe announced to journalists', 'PROPN-VERB-ADP']]\n",
      "[['journalists', 'he'], ['25-39', '22-36', 'PER-PER'], ['journalists this evening Saturday that he', 'DET-NOUN-PROPN-ADP']]\n",
      "[['he', 'government'], ['22-36', '26-40', 'PER-ORG'], ['he had formed a new government', 'VERB-VERB-DET-ADJ']]\n",
      "[['government', 'members'], ['26-40', '27-41', 'ORG-PER'], ['government , following legislative elections last June , with no opposition members', 'PUNCT-VERB-ADJ-NOUN-ADJ-PROPN-PUNCT-ADP-DET-NOUN']]\n",
      "=====\n",
      "\n",
      "\n",
      "The government, which was formed following legislative elections held last month and which the ruling party won by a slim majority, includes 19 ministers all of whom are members of the Zimbabwe African National Union - Patriotic Front.\n",
      "[['government', 'which', 'party', 'ministers', 'all', 'whom', 'members', 'Zimbabwe African National Union - Patriotic Front'], [['26-42', '1'], ['26-43', '3'], ['28-44', '16'], ['1-3', '25'], ['1-4', '26'], ['1-5', '28'], ['1-6', '30'], ['28-2', '33']], ['ORG', 'ORG', 'ORG', 'PER', 'PER', 'PER', 'PER', 'ORG']]\n",
      "=====\n",
      "[['government', 'which'], ['26-42', '26-43', 'ORG-ORG'], ['government , which', 'PUNCT']]\n",
      "[['which', 'party'], ['26-43', '28-44', 'ORG-ORG'], ['which was formed following legislative elections held last month and which the ruling party', 'VERB-VERB-VERB-ADJ-NOUN-VERB-ADJ-NOUN-CCONJ-DET-DET-VERB']]\n",
      "[['party', 'ministers'], ['28-44', '1-3', 'ORG-PER'], ['party won by a slim majority , includes 19 ministers', 'VERB-ADP-DET-ADJ-NOUN-PUNCT-VERB-NUM']]\n",
      "[['ministers', 'all'], ['1-3', '1-4', 'PER-PER'], ['ministers  all', '']]\n",
      "[['all', 'whom'], ['1-4', '1-5', 'PER-PER'], ['all of whom', 'ADP']]\n",
      "[['whom', 'members'], ['1-5', '1-6', 'PER-PER'], ['whom are members', 'VERB']]\n",
      "[['members', 'Zimbabwe African National Union - Patriotic Front'], ['1-6', '28-2', 'PER-ORG'], ['members of the Zimbabwe African National Union - Patriotic Front', 'ADP-DET']]\n",
      "=====\n",
      "\n",
      "\n",
      "The new government consists of 17 ministers and 2 undersecretaries.\n",
      "[['government', 'ministers', 'undersecretaries'], [['26-7', '2'], ['3-8', '6'], ['4-9', '9']], ['ORG', 'PER', 'PER']]\n",
      "=====\n",
      "[['government', 'ministers'], ['26-7', '3-8', 'ORG-PER'], ['government consists of 17 ministers', 'VERB-ADP-NUM']]\n",
      "[['ministers', 'undersecretaries'], ['3-8', '4-9', 'PER-PER'], ['ministers and 2 undersecretaries', 'CCONJ-NUM']]\n",
      "=====\n",
      "\n",
      "\n",
      "The list, announced by President Mugabe at a press conference, reveals that the new government includes 10 new ministers selected from public figures and given ministerial posts for the first time, including a young minister named Simba Makoni appointed as head of the Ministry of Finance and Economic Development under circumstances where the country is witnessing an unprecedented economic crisis.\n",
      "[['President', 'Mugabe', 'government', 'ministers', 'figures', 'minister', 'Simba Makoni', 'head', 'Ministry of Finance and Economic Development', 'country'], [['22-38', '5'], ['22-37', '6'], ['26-10', '16'], ['5-11', '20'], ['6-12', '24'], ['7-13', '37'], ['7-14', '39'], ['7-15', '43'], ['9-16', '46'], ['21-31', '56']], ['PER', 'PER', 'ORG', 'PER', 'PER', 'PER', 'PER', 'PER', 'ORG', 'GPE']]\n",
      "=====\n",
      "[['President', 'Mugabe'], ['22-38', '22-37', 'PER-PER'], ['President  Mugabe', '']]\n",
      "[['Mugabe', 'government'], ['22-37', '26-10', 'PER-ORG'], ['Mugabe at a press conference , reveals that the new government', 'ADP-DET-NOUN-NOUN-PUNCT-VERB-ADP-DET-ADJ']]\n",
      "[['government', 'ministers'], ['26-10', '5-11', 'ORG-PER'], ['government includes 10 new ministers', 'VERB-NUM-ADJ']]\n",
      "[['ministers', 'figures'], ['5-11', '6-12', 'PER-PER'], ['ministers selected from public figures', 'VERB-ADP-ADJ']]\n",
      "[['figures', 'minister'], ['6-12', '7-13', 'PER-PER'], ['figures and given ministerial posts for the first time , including a young minister', 'CCONJ-VERB-ADJ-NOUN-ADP-DET-ADJ-NOUN-PUNCT-VERB-DET-ADJ']]\n",
      "[['minister', 'Simba Makoni'], ['7-13', '7-14', 'PER-PER'], ['minister named Simba Makoni', 'VERB']]\n",
      "[['Simba Makoni', 'head'], ['7-14', '7-15', 'PER-PER'], ['Simba Makoni Makoni appointed as head', 'PROPN-VERB-ADP']]\n",
      "[['head', 'Ministry of Finance and Economic Development'], ['7-15', '9-16', 'PER-ORG'], ['head of the Ministry of Finance and Economic Development', 'ADP-DET']]\n",
      "[['Ministry of Finance and Economic Development', 'country'], ['9-16', '21-31', 'ORG-GPE'], ['Ministry of Finance and Economic Development of Finance and Economic Development under circumstances where the country', 'ADP-PROPN-CCONJ-PROPN-PROPN-ADP-NOUN-ADV-DET']]\n",
      "=====\n",
      "\n",
      "\n",
      "Elsewhere, Stan Modinge retains his appointment as Foreign Minister and Moven Mahashi as Defense.\n",
      "[['Stan Modinge', 'his', 'Minister', 'Moven Mahashi', 'Defense'], [['10-17', '2'], ['10-18', '5'], ['10-19', '9'], ['12-21', '11'], ['12-20', '14']], ['PER', 'PER', 'PER', 'PER', 'PER']]\n",
      "=====\n",
      "[['Stan Modinge', 'his'], ['10-17', '10-18', 'PER-PER'], ['Stan Modinge Modinge retains his', 'PROPN-VERB']]\n",
      "[['his', 'Minister'], ['10-18', '10-19', 'PER-PER'], ['his appointment as Foreign Minister', 'NOUN-ADP-PROPN']]\n",
      "[['Minister', 'Moven Mahashi'], ['10-19', '12-21', 'PER-PER'], ['Minister and Moven Mahashi', 'CCONJ']]\n",
      "[['Moven Mahashi', 'Defense'], ['12-21', '12-20', 'PER-PER'], ['Moven Mahashi Mahashi as Defense', 'PROPN-ADP']]\n",
      "=====\n",
      "\n",
      "\n",
      "In the recent legislative elections, the run-up to which was marked by violence, the ruling party won 62 out of the 150 parliamentary seats, in addition to the thirty seats whose incumbents are appointed by the country's president.\n",
      "[['party', 'incumbents', 'country', 'president'], [['28-22', '19'], ['14-23', '36'], ['21-32', '41'], ['15-24', '43']], ['ORG', 'PER', 'GPE', 'PER']]\n",
      "=====\n",
      "[['party', 'incumbents'], ['28-22', '14-23', 'ORG-PER'], ['party won 62 out of the 150 parliamentary seats , in addition to the thirty seats whose incumbents', 'VERB-NUM-ADP-ADP-DET-NUM-ADJ-NOUN-PUNCT-ADP-NOUN-ADP-DET-NUM-NOUN-DET']]\n",
      "[['incumbents', 'country'], ['14-23', '21-32', 'PER-GPE'], ['incumbents are appointed by the country', 'VERB-VERB-ADP-DET']]\n",
      "[['country', 'president'], ['21-32', '15-24', 'GPE-PER'], [\"country 's president\", 'PART']]\n",
      "=====\n",
      "\n",
      "\n",
      "The opposition won 58 seats, 57 of which were taken by the Movement for Democratic Change, the largest opposition party.\n",
      "[['opposition', 'Movement for Democratic Change', 'party'], [['16-25', '1'], ['17-27', '13'], ['17-28', '21']], ['ORG', 'ORG', 'ORG']]\n",
      "=====\n",
      "[['opposition', 'Movement for Democratic Change'], ['16-25', '17-27', 'ORG-ORG'], ['opposition won 58 seats , 57 of which were taken by the Movement for Democratic Change', 'VERB-NUM-NOUN-PUNCT-NUM-ADP-DET-VERB-VERB-ADP-DET']]\n",
      "[['Movement for Democratic Change', 'party'], ['17-27', '17-28', 'ORG-ORG'], ['Movement for Democratic Change for Democratic Change , the largest opposition party', 'ADP-PROPN-PROPN-PUNCT-DET-ADJ-NOUN']]\n",
      "=====\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for index, entity_list in enumerate(sentences_entity_list):\n",
    "    entities_relations = find_relation(tagged_dict, entity_list[0], entity_list)\n",
    "    print(ACE2004_54_text_list[entity_list[0]])\n",
    "    print(entity_list[1])\n",
    "    print(\"=====\")\n",
    "    for entity_relation in entities_relations:\n",
    "        print(entity_relation)\n",
    "    print(\"=====\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65070669-0a3e-41fd-b8c3-8719ff4c1371",
   "metadata": {},
   "source": [
    "## Snowball for POS Pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f3905b5d-b4b4-4789-8c73-dbcce661d06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import copy\n",
    "from random import shuffle\n",
    "import operator\n",
    "from pandas.errors import EmptyDataError\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3faccd27-6600-4b57-abb6-c413f9d41937",
   "metadata": {},
   "outputs": [],
   "source": [
    "ACE2004_file_dir = \"../Data/relex_processed_data/relex/ACE2004/ground_truth/*.csv\"\n",
    "ACE2004_file_dir_files = glob.glob(ACE2004_file_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "88f5e80e-b75b-4feb-9653-8872c55b18f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_pos_pattern_count(snowball_index, pos_pattern_list):\n",
    "    empty_ct = 0\n",
    "    sum_ct = 0\n",
    "    sum_ct = len(pos_pattern_list)\n",
    "    for index, pos_pattern in enumerate(pos_pattern_list):\n",
    "        if pos_pattern in snowball_index:\n",
    "            snowball_index[pos_pattern] += 1\n",
    "            # sum_ct =sum_ct + 1\n",
    "        elif pos_pattern != pos_pattern:\n",
    "            empty_ct += 1\n",
    "            pass\n",
    "        else:\n",
    "            snowball_index[pos_pattern] = 1\n",
    "            # sum_ct =sum_ct + 1\n",
    "\n",
    "    return snowball_index, empty_ct, sum_ct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cd97ab0e-17ff-478a-858f-591ac903cc0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_snowball(files):\n",
    "    \n",
    "    snowball_index = {}\n",
    "\n",
    "    for file in files:\n",
    "        try:\n",
    "            file_tagged_truth = pd.read_csv(file, sep = \"\\t\")\n",
    "            if len(file_tagged_truth) != 0:\n",
    "                pos_pattern_list = file_tagged_truth.pos_pattern.tolist()\n",
    "                snowball_index = cal_pos_pattern_count(snowball_index, pos_pattern_list)\n",
    "        except EmptyDataError:\n",
    "            print(f\"No columns to parse from file {file}\")\n",
    "            \n",
    "    return snowball_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dfdb79cb-3040-499a-8f02-35940e838649",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_out_rel_type(all_rel, cutoff):\n",
    "    \n",
    "    rel_type_out = []\n",
    "    \n",
    "    dict_count = Counter(all_rel)\n",
    "    val_sum = 0\n",
    "    for value in dict_count.values():\n",
    "        val_sum += value\n",
    "        \n",
    "    for key, value in dict_count.items():\n",
    "        rel_dist = (value/val_sum)*100\n",
    "        if rel_dist < cutoff:\n",
    "            rel_type_out.append(key)\n",
    "    \n",
    "    return rel_type_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b6b8620b-ff6a-4bef-ab21-d72c7f4b0844",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_unique_rel(files, cutoff):\n",
    "    \n",
    "    unique_rel = set()\n",
    "    \n",
    "    unique_rel_dict = {}\n",
    "    unique_rel_set = {}\n",
    "    \n",
    "    all_rel = []\n",
    "    \n",
    "    for file in files:\n",
    "        try:\n",
    "            file_tagged_truth = pd.read_csv(file, sep = \"\\t\")\n",
    "            if len(file_tagged_truth) != 0:\n",
    "                rel_type = file_tagged_truth[\"rel type\"].tolist()\n",
    "                for rel in rel_type:\n",
    "                    all_rel.append(rel)\n",
    "                rel_type = set(rel_type)\n",
    "                unique_rel.update(rel_type)\n",
    "        except EmptyDataError:\n",
    "            print(f\"No columns to parse from file {file}\")\n",
    "    \n",
    "    rel_type_out = remove_out_rel_type(all_rel, cutoff)\n",
    "    \n",
    "    unique_rel.difference_update(set(rel_type_out))\n",
    "    \n",
    "    for rel in unique_rel:\n",
    "        unique_rel_dict[rel] = {}\n",
    "        unique_rel_set[rel] = set()\n",
    "    \n",
    "    return unique_rel_dict, unique_rel_set, rel_type_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4b0dc9b1-c812-483e-a4e6-28a7f956bac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_entity_ids(entity_ids):\n",
    "    \n",
    "    for ids in entity_ids:\n",
    "        ids.sort()\n",
    "        \n",
    "    return entity_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2c98dee-3a89-4f77-ada3-8011469201ee",
   "metadata": {},
   "source": [
    "## Generate Rel Snowball function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f47d71db-cf35-42e9-98e6-506b196f5d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_rel_snowball(files, cutoff):\n",
    "    \n",
    "    snowball_index = {}\n",
    "    \n",
    "    snowball_entity = {}\n",
    "    \n",
    "    snowball_index_rel, snowball_pos_ent_type, rel_type_out = generate_unique_rel(files, cutoff)\n",
    "    \n",
    "    list_empty_ct = []\n",
    "    \n",
    "    list_sum_ct = []\n",
    "    \n",
    "    for rel in snowball_index_rel.keys():\n",
    "        for file in files:\n",
    "            try:\n",
    "                file_tagged_truth = pd.read_csv(file, sep = \"\\t\")\n",
    "                # print(file)\n",
    "                file_tagged_truth = file_tagged_truth[file_tagged_truth[\"pos_pattern\"].notna()]\n",
    "                if len(file_tagged_truth) != 0:\n",
    "                    pos_pattern_list = file_tagged_truth.pos_pattern[file_tagged_truth['rel type'] == rel].tolist()\n",
    "                    \n",
    "                    entities_type = file_tagged_truth[[\"entity 1 mention ID\", \"entity 2 mention ID\", 'entity 1 type', 'entity 2 type']][file_tagged_truth['rel type'] == rel]\n",
    "                    \n",
    "                    if entities_type.empty == False:\n",
    "                        snowball_entity = pos_entity_type_list(entities_type)\n",
    "                        snowball_pos_ent_type[rel].update(snowball_entity)\n",
    "                        \n",
    "                    snowball_index, empty_ct, sum_ct = cal_pos_pattern_count(snowball_index, pos_pattern_list)\n",
    "                    list_empty_ct.append(empty_ct)\n",
    "                    list_sum_ct.append(sum_ct)\n",
    "                    snowball_index_rel[rel].update(snowball_index)\n",
    "            except EmptyDataError:\n",
    "                print(f\"No columns to parse from file {file}\")\n",
    "            \n",
    "    return snowball_index_rel, snowball_pos_ent_type, rel_type_out, list_empty_ct, list_sum_ct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3ded9f10-9168-4c5f-9deb-84e640db43ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos_entity_type_list(entities_type):\n",
    "    \n",
    "    ground_truth_id = entities_type[[\"entity 1 mention ID\", \"entity 2 mention ID\"]].values.tolist()\n",
    "    entities_type = entities_type[['entity 1 type', 'entity 2 type']].values.tolist()\n",
    "    \n",
    "    snowball_entity = set()\n",
    "    \n",
    "    for index, ids in enumerate(ground_truth_id):\n",
    "        gt_dict = {}\n",
    "        gt_dict[ids[0]] = entities_type[index][0]\n",
    "        gt_dict[ids[1]] = entities_type[index][1]\n",
    "        \n",
    "        gt_dict_keys = sort_entity_ids([ids])\n",
    "        \n",
    "        entity1 = gt_dict[gt_dict_keys[0][0]]\n",
    "        entity2 = gt_dict[gt_dict_keys[0][1]]\n",
    "        \n",
    "        if entity1 == entity1 and entity2 == entity2:\n",
    "            tmp = entity1 + \"-\" + entity2\n",
    "            snowball_entity.add(tmp)\n",
    "    \n",
    "    # snowball_entity = set()\n",
    "    # for index, pos_pattern in enumerate(pos_pattern_list):\n",
    "    #     tmp = entity1[index] + \"-\" + entity2[index]\n",
    "    #     print(tmp)\n",
    "    #     snowball_entity.add(tmp)\n",
    "        # if pos_pattern in snowball_entity:\n",
    "        #     tmp = entity1[index] + \"-\" + entity2[index]\n",
    "        #     # tmp_set = snowball_entity[pos_pattern]\n",
    "        #     snowball_entity.add(tmp)\n",
    "        #     # print(pos_pattern, \"-->\", tmp)\n",
    "        #     # snowball_entity[pos_pattern] = tmp_set\n",
    "        # elif pos_pattern != pos_pattern:\n",
    "        #     pass\n",
    "        # else:\n",
    "        #     tmp = entity1[index] + \"-\" + entity2[index]\n",
    "        #     # print(pos_pattern, \"==>\", tmp)\n",
    "        #     snowball_entity = {tmp}\n",
    "        #     # snowball_entity[pos_pattern] = {tmp}\n",
    "    \n",
    "    return snowball_entity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d0a6ea73-4204-472c-907e-9baebabcc505",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_rank(snowball_index):\n",
    "    \n",
    "    snowball_pos_pattern = {}\n",
    "    total_index = 0\n",
    "    \n",
    "    for value in snowball_index.values():\n",
    "        total_index += value\n",
    "    \n",
    "    for key, value in snowball_index.items():\n",
    "        snowball_pos_pattern[key] = value/total_index\n",
    "    \n",
    "    return snowball_pos_pattern, total_index\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1a0d4409-4b0c-430b-b159-dd57b7cc0d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_dict(snowball_pos_pattern):\n",
    "    return dict(sorted(snowball_pos_pattern.items(), key=operator.itemgetter(1), reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "04e1d45e-5a99-4e35-b4c6-9ec7cb27dde7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_out(snowball_pos_pattern):\n",
    "    snowball_pos_pattern_values = np.array(list(snowball_pos_pattern.values()))\n",
    "    snowball_pos_pattern_keys = list(snowball_pos_pattern.keys())\n",
    "    \n",
    "    mean = np.mean(snowball_pos_pattern_values, axis=0)\n",
    "    sd = np.std(snowball_pos_pattern_values, axis=0)\n",
    "    \n",
    "    final_list = [x for x in snowball_pos_pattern_values if (x >= mean - 2 * sd)]\n",
    "    final_list = [x for x in final_list if (x <= mean + 2 * sd)]\n",
    "    \n",
    "    snowball_pos_pattern_keys = snowball_pos_pattern_keys[:len(final_list)]\n",
    "    \n",
    "    snowball_pos_pattern_filter = dict(zip(snowball_pos_pattern_keys, final_list))\n",
    "    \n",
    "    return snowball_pos_pattern_filter\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da5c58a6-e56d-4aa4-8209-3e419b5300b7",
   "metadata": {},
   "source": [
    "## Find Valid POS Pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c03ea099-e236-4e7c-ae0f-8d49f25ba705",
   "metadata": {},
   "outputs": [],
   "source": [
    "def re_rank_snowball(snowball_pos_pattern, snowball_key, total_index):\n",
    "    \n",
    "    for key in snowball_pos_pattern.keys():\n",
    "        \n",
    "        if snowball_key == key:\n",
    "            snowball_pos_pattern[key] = ((snowball_pos_pattern[key]*(total_index)) + 1)/(total_index + 1)\n",
    "        else:\n",
    "            snowball_pos_pattern[key] = (snowball_pos_pattern[key]*(total_index))/(total_index + 1)\n",
    "            \n",
    "    return snowball_pos_pattern\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "17df3dc4-aac8-407e-8be0-766cc3b3cf44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_pos_pattern_and_update(snowball_pos_pattern, pos_pattern, total_index, re_compute = False):\n",
    "    \n",
    "    if pos_pattern in snowball_pos_pattern.keys():\n",
    "        score = snowball_pos_pattern[pos_pattern]\n",
    "        if re_compute == True:\n",
    "            print(\"\\n=====Matched with SnowBall -- Re-Computing Snowball=====\\n\")\n",
    "            snowball_pos_pattern = re_rank_snowball(snowball_pos_pattern, pos_pattern, total_index)\n",
    "        return score, snowball_pos_pattern\n",
    "    else:\n",
    "        return False, snowball_pos_pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5b05f15e-21b2-4182-915d-59ead6442a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_rel_pos_pattern_and_update(snowball_pos_pattern_filter_rel, pos_pattern, filter_rel_types, total_index_rel, re_compute = False):\n",
    "    \n",
    "    pos_len = len(snowball_pos_pattern_filter_rel) - 1\n",
    "    max_score = -1\n",
    "    rel_type = ''\n",
    "\n",
    "    for index, (snowball_pos_pattern_key, snowball_pos_pattern_value) in enumerate(snowball_pos_pattern_filter_rel.items()):\n",
    "        # print(\"==>\", snowball_pos_pattern_key, filter_rel_types)\n",
    "        if snowball_pos_pattern_key in filter_rel_types:\n",
    "            if pos_pattern in snowball_pos_pattern_value.keys():\n",
    "                score = snowball_pos_pattern_value[pos_pattern]\n",
    "                # print(\"==>\", snowball_pos_pattern_key, pos_pattern, score)\n",
    "\n",
    "                if score > max_score:\n",
    "                    max_score = score\n",
    "                    rel_type = snowball_pos_pattern_key\n",
    "\n",
    "                if re_compute == True and index == pos_len:\n",
    "                    print(\"\\n=====Matched with SnowBall -- Re-Computing Snowball=====\\n\")\n",
    "                    snowball_pos_pattern_filter_rel[rel_type] = re_rank_snowball(snowball_pos_pattern_filter_rel[rel_type], pos_pattern, total_index_rel[rel_type])\n",
    "                \n",
    "    if max_score != -1:\n",
    "        return max_score, rel_type, snowball_pos_pattern_filter_rel\n",
    "    else:\n",
    "        return False, False, snowball_pos_pattern_filter_rel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5a7423bc-4e06-4c38-b539-00029acdfaa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_valid_rel_type(snowball_pos_ent_type, entities_type):\n",
    "    \n",
    "    filter_rel_types = []\n",
    "    for key, value in snowball_pos_ent_type.items():\n",
    "        if entities_type in value:\n",
    "            filter_rel_types.append(key)\n",
    "            \n",
    "    return filter_rel_types\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d8abb889-435c-4cc0-a4f7-a98e72f69a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Global snowball\n",
    "\n",
    "ACE2004_file_dir_files_sample = ACE2004_file_dir_files[:int(len(ACE2004_file_dir_files) * .70)]\n",
    "# snowball_index = generate_snowball(ACE2004_file_dir_files_sample)\n",
    "# snowball_pos_pattern, total_index = cal_rank(snowball_index)\n",
    "# snowball_pos_pattern = sort_dict(snowball_pos_pattern)\n",
    "# snowball_pos_pattern_filter = remove_out(snowball_pos_pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "91cea5c5-1e06-4142-a820-a42d1561c479",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No columns to parse from file ../Data/relex_processed_data/relex/ACE2004/ground_truth\\CNN20001014.1400.0553.csv\n",
      "No columns to parse from file ../Data/relex_processed_data/relex/ACE2004/ground_truth\\CNN20001014.1400.0553.csv\n",
      "No columns to parse from file ../Data/relex_processed_data/relex/ACE2004/ground_truth\\CNN20001014.1400.0553.csv\n",
      "No columns to parse from file ../Data/relex_processed_data/relex/ACE2004/ground_truth\\CNN20001014.1400.0553.csv\n"
     ]
    }
   ],
   "source": [
    "#Relation focused snowball\n",
    "\n",
    "snowball_index_rel, snowball_pos_ent_type, rel_type_out, list_empty_ct, list_sum_ct = generate_rel_snowball(ACE2004_file_dir_files_sample, 10)\n",
    "\n",
    "total_index_rel = {}\n",
    "snowball_pos_pattern_filter_rel = {}\n",
    "\n",
    "for key, value in snowball_index_rel.items():\n",
    "    snowball_pos_pattern, total_index_rel[key] = cal_rank(value)\n",
    "    snowball_pos_pattern = sort_dict(snowball_pos_pattern)\n",
    "    snowball_pos_pattern_filter_rel[key] = remove_out(snowball_pos_pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8a405a5f-e0d9-4dfd-b505-9d35e724949a",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Harare 7-15 (AFP)-\n",
      "[['Harare', 'AFP)-'], [['19-1', '0'], ['20-29', '5']], ['GPE', 'ORG']]\n",
      "+++++\n",
      "[['Harare', 'AFP)-'], ['19-1', '20-29', 'GPE-ORG'], ['Harare 7 - 15 ( AFP)-', 'NUM-SYM-NUM-PUNCT']]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'snowball_pos_pattern_filter' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_39064/409375266.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mentity_relation\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentities_relations\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mentity_relation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m         \u001b[0mscore\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msnowball_pos_pattern\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_pos_pattern_and_update\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msnowball_pos_pattern_filter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mentity_relation\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtotal_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"POS Pattern Score: \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mscore\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'snowball_pos_pattern_filter' is not defined"
     ]
    }
   ],
   "source": [
    "#Global snowball\n",
    "\n",
    "valid_relationships = []\n",
    "valid_ids = []\n",
    "\n",
    "for index, entity_list in enumerate(sentences_entity_list):\n",
    "    entities_relations = find_relation(tagged_dict, entity_list[0], entity_list)\n",
    "    print(ACE2004_54_text_list[entity_list[0]])\n",
    "    print(entity_list[1])\n",
    "    print(\"+++++\")\n",
    "    for entity_relation in entities_relations:\n",
    "        print(entity_relation)\n",
    "        score, snowball_pos_pattern = check_pos_pattern_and_update(snowball_pos_pattern_filter, entity_relation[2][1], total_index)\n",
    "        print(\"POS Pattern Score: \", score)\n",
    "        if score != False:\n",
    "            valid_relationships.append(entity_relation[2][0])\n",
    "            valid_ids.append(entity_relation[1])\n",
    "    print(\"=====\")\n",
    "    print(\"\\n\")\n",
    "print(valid_relationships)\n",
    "print(valid_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1ee3908c-a105-4dc0-b2d0-73970d0bceef",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Harare 7-15 (AFP)-\n",
      "[['Harare', 'AFP)-'], [['19-1', '0'], ['20-29', '5']], ['GPE', 'ORG']]\n",
      "+++++\n",
      "[['Harare', 'AFP)-'], ['19-1', '20-29', 'GPE-ORG'], ['Harare 7 - 15 ( AFP)-', 'NUM-SYM-NUM-PUNCT']]\n",
      "POS Pattern Score:  False\n",
      "Relationship Type:  False\n",
      "=====\n",
      "\n",
      "\n",
      "Zimbabwe's President Robert Mugabe announced to journalists this evening Saturday that he had formed a new government, following legislative elections last June, with no opposition members included.\n",
      "[['Zimbabwe', 'President', 'Robert Mugabe', 'journalists', 'he', 'government', 'members'], [['21-30', '0'], ['22-34', '2'], ['22-35', '3'], ['25-39', '7'], ['22-36', '12'], ['26-40', '17'], ['27-41', '28']], ['GPE', 'PER', 'PER', 'PER', 'PER', 'ORG', 'PER']]\n",
      "+++++\n",
      "[['Zimbabwe', 'President'], ['21-30', '22-34', 'GPE-PER'], [\"Zimbabwe 's President\", 'PART']]\n",
      "POS Pattern Score:  0.017553191489361703\n",
      "Relationship Type:  EMP-ORG\n",
      "[['President', 'Robert Mugabe'], ['22-34', '22-35', 'PER-PER'], ['President  Robert Mugabe', '']]\n",
      "POS Pattern Score:  False\n",
      "Relationship Type:  False\n",
      "[['Robert Mugabe', 'journalists'], ['22-35', '25-39', 'PER-PER'], ['Robert Mugabe Mugabe announced to journalists', 'PROPN-VERB-ADP']]\n",
      "POS Pattern Score:  False\n",
      "Relationship Type:  False\n",
      "[['journalists', 'he'], ['25-39', '22-36', 'PER-PER'], ['journalists this evening Saturday that he', 'DET-NOUN-PROPN-ADP']]\n",
      "POS Pattern Score:  False\n",
      "Relationship Type:  False\n",
      "[['he', 'government'], ['22-36', '26-40', 'PER-ORG'], ['he had formed a new government', 'VERB-VERB-DET-ADJ']]\n",
      "POS Pattern Score:  0.0010638297872340426\n",
      "Relationship Type:  EMP-ORG\n",
      "[['government', 'members'], ['26-40', '27-41', 'ORG-PER'], ['government , following legislative elections last June , with no opposition members', 'PUNCT-VERB-ADJ-NOUN-ADJ-PROPN-PUNCT-ADP-DET-NOUN']]\n",
      "POS Pattern Score:  False\n",
      "Relationship Type:  False\n",
      "=====\n",
      "\n",
      "\n",
      "The government, which was formed following legislative elections held last month and which the ruling party won by a slim majority, includes 19 ministers all of whom are members of the Zimbabwe African National Union - Patriotic Front.\n",
      "[['government', 'which', 'party', 'ministers', 'all', 'whom', 'members', 'Zimbabwe African National Union - Patriotic Front'], [['26-42', '1'], ['26-43', '3'], ['28-44', '16'], ['1-3', '25'], ['1-4', '26'], ['1-5', '28'], ['1-6', '30'], ['28-2', '33']], ['ORG', 'ORG', 'ORG', 'PER', 'PER', 'PER', 'PER', 'ORG']]\n",
      "+++++\n",
      "[['government', 'which'], ['26-42', '26-43', 'ORG-ORG'], ['government , which', 'PUNCT']]\n",
      "POS Pattern Score:  False\n",
      "Relationship Type:  False\n",
      "[['which', 'party'], ['26-43', '28-44', 'ORG-ORG'], ['which was formed following legislative elections held last month and which the ruling party', 'VERB-VERB-VERB-ADJ-NOUN-VERB-ADJ-NOUN-CCONJ-DET-DET-VERB']]\n",
      "POS Pattern Score:  False\n",
      "Relationship Type:  False\n",
      "[['party', 'ministers'], ['28-44', '1-3', 'ORG-PER'], ['party won by a slim majority , includes 19 ministers', 'VERB-ADP-DET-ADJ-NOUN-PUNCT-VERB-NUM']]\n",
      "POS Pattern Score:  False\n",
      "Relationship Type:  False\n",
      "[['ministers', 'all'], ['1-3', '1-4', 'PER-PER'], ['ministers  all', '']]\n",
      "POS Pattern Score:  False\n",
      "Relationship Type:  False\n",
      "[['all', 'whom'], ['1-4', '1-5', 'PER-PER'], ['all of whom', 'ADP']]\n",
      "POS Pattern Score:  0.018900343642611683\n",
      "Relationship Type:  GPE-AFF\n",
      "[['whom', 'members'], ['1-5', '1-6', 'PER-PER'], ['whom are members', 'VERB']]\n",
      "POS Pattern Score:  0.013745704467353952\n",
      "Relationship Type:  GPE-AFF\n",
      "[['members', 'Zimbabwe African National Union - Patriotic Front'], ['1-6', '28-2', 'PER-ORG'], ['members of the Zimbabwe African National Union - Patriotic Front', 'ADP-DET']]\n",
      "POS Pattern Score:  0.018085106382978722\n",
      "Relationship Type:  EMP-ORG\n",
      "=====\n",
      "\n",
      "\n",
      "The new government consists of 17 ministers and 2 undersecretaries.\n",
      "[['government', 'ministers', 'undersecretaries'], [['26-7', '2'], ['3-8', '6'], ['4-9', '9']], ['ORG', 'PER', 'PER']]\n",
      "+++++\n",
      "[['government', 'ministers'], ['26-7', '3-8', 'ORG-PER'], ['government consists of 17 ministers', 'VERB-ADP-NUM']]\n",
      "POS Pattern Score:  0.0005319148936170213\n",
      "Relationship Type:  EMP-ORG\n",
      "[['ministers', 'undersecretaries'], ['3-8', '4-9', 'PER-PER'], ['ministers and 2 undersecretaries', 'CCONJ-NUM']]\n",
      "POS Pattern Score:  False\n",
      "Relationship Type:  False\n",
      "=====\n",
      "\n",
      "\n",
      "The list, announced by President Mugabe at a press conference, reveals that the new government includes 10 new ministers selected from public figures and given ministerial posts for the first time, including a young minister named Simba Makoni appointed as head of the Ministry of Finance and Economic Development under circumstances where the country is witnessing an unprecedented economic crisis.\n",
      "[['President', 'Mugabe', 'government', 'ministers', 'figures', 'minister', 'Simba Makoni', 'head', 'Ministry of Finance and Economic Development', 'country'], [['22-38', '5'], ['22-37', '6'], ['26-10', '16'], ['5-11', '20'], ['6-12', '24'], ['7-13', '37'], ['7-14', '39'], ['7-15', '43'], ['9-16', '46'], ['21-31', '56']], ['PER', 'PER', 'ORG', 'PER', 'PER', 'PER', 'PER', 'PER', 'ORG', 'GPE']]\n",
      "+++++\n",
      "[['President', 'Mugabe'], ['22-38', '22-37', 'PER-PER'], ['President  Mugabe', '']]\n",
      "POS Pattern Score:  False\n",
      "Relationship Type:  False\n",
      "[['Mugabe', 'government'], ['22-37', '26-10', 'PER-ORG'], ['Mugabe at a press conference , reveals that the new government', 'ADP-DET-NOUN-NOUN-PUNCT-VERB-ADP-DET-ADJ']]\n",
      "POS Pattern Score:  False\n",
      "Relationship Type:  False\n",
      "[['government', 'ministers'], ['26-10', '5-11', 'ORG-PER'], ['government includes 10 new ministers', 'VERB-NUM-ADJ']]\n",
      "POS Pattern Score:  False\n",
      "Relationship Type:  False\n",
      "[['ministers', 'figures'], ['5-11', '6-12', 'PER-PER'], ['ministers selected from public figures', 'VERB-ADP-ADJ']]\n",
      "POS Pattern Score:  0.001718213058419244\n",
      "Relationship Type:  GPE-AFF\n",
      "[['figures', 'minister'], ['6-12', '7-13', 'PER-PER'], ['figures and given ministerial posts for the first time , including a young minister', 'CCONJ-VERB-ADJ-NOUN-ADP-DET-ADJ-NOUN-PUNCT-VERB-DET-ADJ']]\n",
      "POS Pattern Score:  False\n",
      "Relationship Type:  False\n",
      "[['minister', 'Simba Makoni'], ['7-13', '7-14', 'PER-PER'], ['minister named Simba Makoni', 'VERB']]\n",
      "POS Pattern Score:  0.013745704467353952\n",
      "Relationship Type:  GPE-AFF\n",
      "[['Simba Makoni', 'head'], ['7-14', '7-15', 'PER-PER'], ['Simba Makoni Makoni appointed as head', 'PROPN-VERB-ADP']]\n",
      "POS Pattern Score:  False\n",
      "Relationship Type:  False\n",
      "[['head', 'Ministry of Finance and Economic Development'], ['7-15', '9-16', 'PER-ORG'], ['head of the Ministry of Finance and Economic Development', 'ADP-DET']]\n",
      "POS Pattern Score:  0.018085106382978722\n",
      "Relationship Type:  EMP-ORG\n",
      "[['Ministry of Finance and Economic Development', 'country'], ['9-16', '21-31', 'ORG-GPE'], ['Ministry of Finance and Economic Development of Finance and Economic Development under circumstances where the country', 'ADP-PROPN-CCONJ-PROPN-PROPN-ADP-NOUN-ADV-DET']]\n",
      "POS Pattern Score:  False\n",
      "Relationship Type:  False\n",
      "=====\n",
      "\n",
      "\n",
      "Elsewhere, Stan Modinge retains his appointment as Foreign Minister and Moven Mahashi as Defense.\n",
      "[['Stan Modinge', 'his', 'Minister', 'Moven Mahashi', 'Defense'], [['10-17', '2'], ['10-18', '5'], ['10-19', '9'], ['12-21', '11'], ['12-20', '14']], ['PER', 'PER', 'PER', 'PER', 'PER']]\n",
      "+++++\n",
      "[['Stan Modinge', 'his'], ['10-17', '10-18', 'PER-PER'], ['Stan Modinge Modinge retains his', 'PROPN-VERB']]\n",
      "POS Pattern Score:  False\n",
      "Relationship Type:  False\n",
      "[['his', 'Minister'], ['10-18', '10-19', 'PER-PER'], ['his appointment as Foreign Minister', 'NOUN-ADP-PROPN']]\n",
      "POS Pattern Score:  False\n",
      "Relationship Type:  False\n",
      "[['Minister', 'Moven Mahashi'], ['10-19', '12-21', 'PER-PER'], ['Minister and Moven Mahashi', 'CCONJ']]\n",
      "POS Pattern Score:  False\n",
      "Relationship Type:  False\n",
      "[['Moven Mahashi', 'Defense'], ['12-21', '12-20', 'PER-PER'], ['Moven Mahashi Mahashi as Defense', 'PROPN-ADP']]\n",
      "POS Pattern Score:  0.0011668611435239206\n",
      "Relationship Type:  PHYS\n",
      "=====\n",
      "\n",
      "\n",
      "In the recent legislative elections, the run-up to which was marked by violence, the ruling party won 62 out of the 150 parliamentary seats, in addition to the thirty seats whose incumbents are appointed by the country's president.\n",
      "[['party', 'incumbents', 'country', 'president'], [['28-22', '19'], ['14-23', '36'], ['21-32', '41'], ['15-24', '43']], ['ORG', 'PER', 'GPE', 'PER']]\n",
      "+++++\n",
      "[['party', 'incumbents'], ['28-22', '14-23', 'ORG-PER'], ['party won 62 out of the 150 parliamentary seats , in addition to the thirty seats whose incumbents', 'VERB-NUM-ADP-ADP-DET-NUM-ADJ-NOUN-PUNCT-ADP-NOUN-ADP-DET-NUM-NOUN-DET']]\n",
      "POS Pattern Score:  False\n",
      "Relationship Type:  False\n",
      "[['incumbents', 'country'], ['14-23', '21-32', 'PER-GPE'], ['incumbents are appointed by the country', 'VERB-VERB-ADP-DET']]\n",
      "POS Pattern Score:  0.003500583430571762\n",
      "Relationship Type:  PHYS\n",
      "[['country', 'president'], ['21-32', '15-24', 'GPE-PER'], [\"country 's president\", 'PART']]\n",
      "POS Pattern Score:  0.017553191489361703\n",
      "Relationship Type:  EMP-ORG\n",
      "=====\n",
      "\n",
      "\n",
      "The opposition won 58 seats, 57 of which were taken by the Movement for Democratic Change, the largest opposition party.\n",
      "[['opposition', 'Movement for Democratic Change', 'party'], [['16-25', '1'], ['17-27', '13'], ['17-28', '21']], ['ORG', 'ORG', 'ORG']]\n",
      "+++++\n",
      "[['opposition', 'Movement for Democratic Change'], ['16-25', '17-27', 'ORG-ORG'], ['opposition won 58 seats , 57 of which were taken by the Movement for Democratic Change', 'VERB-NUM-NOUN-PUNCT-NUM-ADP-DET-VERB-VERB-ADP-DET']]\n",
      "POS Pattern Score:  False\n",
      "Relationship Type:  False\n",
      "[['Movement for Democratic Change', 'party'], ['17-27', '17-28', 'ORG-ORG'], ['Movement for Democratic Change for Democratic Change , the largest opposition party', 'ADP-PROPN-PROPN-PUNCT-DET-ADJ-NOUN']]\n",
      "POS Pattern Score:  False\n",
      "Relationship Type:  False\n",
      "=====\n",
      "\n",
      "\n",
      "[['Zimbabwe', 'President'], ['he', 'government'], ['all', 'whom'], ['whom', 'members'], ['members', 'Zimbabwe African National Union - Patriotic Front'], ['government', 'ministers'], ['ministers', 'figures'], ['minister', 'Simba Makoni'], ['head', 'Ministry of Finance and Economic Development'], ['Moven Mahashi', 'Defense'], ['incumbents', 'country'], ['country', 'president']]\n",
      "\n",
      "\n",
      "['GPE-PER', 'PER-ORG', 'PER-PER', 'PER-PER', 'PER-ORG', 'ORG-PER', 'PER-PER', 'PER-PER', 'PER-ORG', 'PER-PER', 'PER-GPE', 'GPE-PER']\n",
      "\n",
      "\n",
      "[\"Zimbabwe 's President\", 'he had formed a new government', 'all of whom', 'whom are members', 'members of the Zimbabwe African National Union - Patriotic Front', 'government consists of 17 ministers', 'ministers selected from public figures', 'minister named Simba Makoni', 'head of the Ministry of Finance and Economic Development', 'Moven Mahashi Mahashi as Defense', 'incumbents are appointed by the country', \"country 's president\"]\n",
      "\n",
      "\n",
      "['PART', 'VERB-VERB-DET-ADJ', 'ADP', 'VERB', 'ADP-DET', 'VERB-ADP-NUM', 'VERB-ADP-ADJ', 'VERB', 'ADP-DET', 'PROPN-ADP', 'VERB-VERB-ADP-DET', 'PART']\n",
      "\n",
      "\n",
      "['EMP-ORG', 'EMP-ORG', 'GPE-AFF', 'GPE-AFF', 'EMP-ORG', 'EMP-ORG', 'GPE-AFF', 'GPE-AFF', 'EMP-ORG', 'PHYS', 'PHYS', 'EMP-ORG']\n",
      "\n",
      "\n",
      "[['21-30', '22-34'], ['22-36', '26-40'], ['1-4', '1-5'], ['1-5', '1-6'], ['1-6', '28-2'], ['26-7', '3-8'], ['5-11', '6-12'], ['7-13', '7-14'], ['7-15', '9-16'], ['12-21', '12-20'], ['14-23', '21-32'], ['21-32', '15-24']]\n"
     ]
    }
   ],
   "source": [
    "#Relation focused snowball\n",
    "\n",
    "valid_relationships = []\n",
    "valid_ids = []\n",
    "valid_pos = []\n",
    "valid_rel = []\n",
    "valid_ents = []\n",
    "valid_ents_typ = []\n",
    "\n",
    "for index, entity_list in enumerate(sentences_entity_list):\n",
    "    entities_relations = find_relation(tagged_dict, entity_list[0], entity_list)\n",
    "    print(ACE2004_54_text_list[entity_list[0]])\n",
    "    print(entity_list[1])\n",
    "    print(\"+++++\")\n",
    "    for entity_relation in entities_relations:\n",
    "        print(entity_relation)\n",
    "        filter_rel_types = filter_valid_rel_type(snowball_pos_ent_type, entity_relation[1][2])\n",
    "        score, rel_type, snowball_pos_pattern_filter_rel = check_rel_pos_pattern_and_update(snowball_pos_pattern_filter_rel, entity_relation[2][1], filter_rel_types, total_index_rel)\n",
    "        print(\"POS Pattern Score: \", score)\n",
    "        print(\"Relationship Type: \", rel_type)\n",
    "        if score != False:\n",
    "            valid_ents.append([entity_relation[0][0], entity_relation[0][1]])\n",
    "            valid_ents_typ.append(entity_relation[1][2])\n",
    "            valid_relationships.append(entity_relation[2][0])\n",
    "            valid_pos.append(entity_relation[2][1])\n",
    "            valid_rel.append(rel_type)\n",
    "            valid_ids.append(entity_relation[1][:2])\n",
    "    print(\"=====\")\n",
    "    print(\"\\n\")\n",
    "\n",
    "print(valid_ents)\n",
    "print(\"\\n\")\n",
    "print(valid_ents_typ)\n",
    "print(\"\\n\")\n",
    "print(valid_relationships)\n",
    "print(\"\\n\")\n",
    "print(valid_pos)\n",
    "print(\"\\n\")\n",
    "print(valid_rel)\n",
    "print(\"\\n\")\n",
    "print(valid_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f4af4471-b4a1-4817-8d7f-7d1d6e73bc48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['21-30', '22-34'],\n",
       " ['22-36', '26-40'],\n",
       " ['1-4', '1-5'],\n",
       " ['1-5', '1-6'],\n",
       " ['1-6', '28-2'],\n",
       " ['26-7', '3-8'],\n",
       " ['5-11', '6-12'],\n",
       " ['7-13', '7-14'],\n",
       " ['7-15', '9-16'],\n",
       " ['12-21', '12-20'],\n",
       " ['14-23', '21-32'],\n",
       " ['21-32', '15-24']]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b6250b7-7fb3-498c-a58a-291f7cfdc79c",
   "metadata": {},
   "source": [
    "# Benchmarking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea89fdac-e586-4e21-a564-0e0afc08a98f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark(valid_relationships, valid_ids, valid_rel, ground_truth, rel_type_out):\n",
    "    true_positives = 0\n",
    "    false_positives = 0\n",
    "    false_negatives = 0\n",
    "    \n",
    "    valid_relationships = list(map(str, valid_relationships))\n",
    "    ground_truth = ground_truth[ground_truth[\"pos_pattern\"].notna()]\n",
    "    ground_truth_relationships = list(map(str, ground_truth[\"span\"].tolist()))\n",
    "    ground_truth_relationships_type = list(map(str, ground_truth[\"rel type\"].tolist()))\n",
    "    \n",
    "    ground_truth_id = ground_truth[[\"entity 1 mention ID\", \"entity 2 mention ID\"]].values.tolist()\n",
    "    ground_truth_id = sort_entity_ids(ground_truth_id)\n",
    "    valid_fixed_ids = []\n",
    "    for ids in valid_ids:\n",
    "        valid_fixed_ids.append(ids[:2])\n",
    "    valid_ids = sort_entity_ids(valid_fixed_ids)\n",
    "    pred_rel = ''\n",
    "    ground_truth_rel = ''\n",
    "    \n",
    "    print(\"\\n\")\n",
    "    print(\"DETECTED RELATIONSHIPS: \")\n",
    "    [print(relationships) for relationships in valid_relationships]\n",
    "    print(\"\\n\")\n",
    "    print(\"GROUND TRUTH RELATIONSHIPS: \")\n",
    "    [print(relationships) for relationships in ground_truth_relationships]\n",
    "    print(\"\\n\")\n",
    "    \n",
    "#     for relationship in valid_relationships:\n",
    "#         if df.get_close_matches(relationship, ground_truth, cutoff=.8):\n",
    "#             print(\"Matched Relationship: \", df.get_close_matches(relationship, ground_truth, cutoff=.8)[0])\n",
    "#             true_positives += 1\n",
    "#         else:\n",
    "#             false_positives += 1\n",
    "    \n",
    "#     for relationship in ground_truth:\n",
    "#         if len(df.get_close_matches(relationship, valid_relationships, cutoff=.8)):\n",
    "#             false_negatives += 1\n",
    "\n",
    "    pred_grd_rel_type = []\n",
    "    for index, ids in enumerate(valid_ids):\n",
    "        if ids in ground_truth_id:\n",
    "            if len(valid_rel) != 0:\n",
    "                id_index = ground_truth_id.index(ids)\n",
    "                ground_truth_rel = ground_truth_relationships_type[id_index]\n",
    "                pred_rel = valid_rel[index]\n",
    "                pred_grd_rel_type.append([pred_rel, ground_truth_rel])\n",
    "                if ground_truth_rel not in rel_type_out:\n",
    "                    if ground_truth_rel == pred_rel:\n",
    "                        print(\"\\nMatched Relationship: %s with relationship %s\" %(valid_relationships[index], pred_rel))\n",
    "                        true_positives += 1\n",
    "                    else:\n",
    "                        print(\"\\nIndex matched for ''%s'' but relationship type not matched with PREDICTED as: %s and ACTUAL as: %s\" %(valid_relationships[index], pred_rel, ground_truth_rel))\n",
    "                        false_positives += 1\n",
    "                else:\n",
    "                    print(\"Ignoring less significant relationalship type ''%s''\" %(ground_truth_rel))\n",
    "            else:\n",
    "                print(\"\\nMatched Relationship: %s\" %(valid_relationships[index]))\n",
    "                true_positives += 1\n",
    "        else:\n",
    "            pred_grd_rel_type.append([valid_rel[index], 'NA'])\n",
    "            false_positives += 1\n",
    "    \n",
    "    for index, ids in enumerate(ground_truth_id):\n",
    "        if ids not in valid_ids:\n",
    "            false_negatives += 1\n",
    "            \n",
    "    return true_positives, false_positives, false_negatives, pred_grd_rel_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b379ade0-7685-4b78-969b-aa3f766c930f",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_positives, false_positives, false_negatives, _ = benchmark(valid_relationships, valid_ids, [], ACE2004_54_truth[[\"rel type\", \"entity 1 mention ID\", \"entity 2 mention ID\", \"pos_pattern\", \"span\"]], rel_type_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3161e026-8d1d-4147-b81f-0c88f42f7757",
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision(true_positives, false_positives):\n",
    "    print(\"Precision: \", true_positives/(true_positives + false_positives))\n",
    "    return true_positives/(true_positives + false_positives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8988747-a7e6-48c0-b14f-6ab77bd2c57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall(true_positives, false_negatives):\n",
    "    print(\"Recall: \", true_positives/(true_positives + false_negatives))\n",
    "    return true_positives/(true_positives + false_negatives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6541f90-562b-48c3-8d90-17ca188b277d",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_positives, false_positives, false_negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993b80d2-9a6f-412a-b491-c281f55bdc13",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision(true_positives, false_positives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ec705e-1294-43cd-b0c4-94a946771b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "recall(true_positives, false_negatives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19fa840d-9dce-4137-963a-10f3b8dbf8cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark_dataset(tagged_token_files, ground_truth_files, raw_text_files, snowball_pos_pattern, total_index, snowball_pos_ent_type = [], rel_type_out = [], re_compute = False, rel_snowball = False):\n",
    "    \n",
    "    all_precision = []\n",
    "    all_recall = []\n",
    "    \n",
    "    all_valid_relationships = []\n",
    "    all_valid_pos = []\n",
    "    all_valid_rel = []\n",
    "    all_valid_ents = []\n",
    "    all_valid_ents_type = []\n",
    "    all_pred_grd_rel_type = []\n",
    "    \n",
    "    for index, file in enumerate(tagged_token_files):\n",
    "        \n",
    "        try: \n",
    "            print(\"==================Start of File %d==================\" % index)\n",
    "            print(\"Reading Files: \" + raw_text_files[index] + \"\\n- \" + file + \"\\n- \" + ground_truth_files[index])\n",
    "            print(\"\\n\")\n",
    "            tagged_token = pd.read_csv(file, sep = \"\\t\")\n",
    "            ground_truth = pd.read_csv(ground_truth_files[index], sep = \"\\t\")\n",
    "            raw_text = open(raw_text_files[index], \"r\", encoding=\"utf8\")\n",
    "            raw_text_list = raw_text.readlines()\n",
    "            raw_text_list = [sentence for sentence in raw_text_list if sentence != '\\n']\n",
    "            raw_text_list = [sentence.replace(' \\n', '') for sentence in raw_text_list]\n",
    "            \n",
    "            tagged_token_dict = create_tagged_dict(tagged_token)\n",
    "\n",
    "            sentences_entity_list = []\n",
    "\n",
    "            for index, sentence in enumerate(raw_text_list):\n",
    "                sentence_nlp = nlp(sentence)\n",
    "                \n",
    "                entities, indices, entities_types = sentence_entity(tagged_token_dict, index, sentence_nlp, False)\n",
    "                # sent_roots, sent_roots_index = extract_root(tagged_token_dict, index, sentence_nlp)\n",
    "                sentences_entity_list.append([index, [entities, indices, entities_types]])\n",
    "                \n",
    "            # sentences_entity_list = filter_sentences(sentences_entity_list)\n",
    "\n",
    "            valid_relationships = []\n",
    "            valid_ids = []\n",
    "            valid_pos = []\n",
    "            valid_rel = []\n",
    "            valid_ents = []\n",
    "            valid_ents_typ = []\n",
    "\n",
    "            for index, entity_list in enumerate(sentences_entity_list):\n",
    "                entities_relations = find_relation(tagged_token_dict, entity_list[0], entity_list)\n",
    "                print(raw_text_list[entity_list[0]])\n",
    "                # print(entity_list[1])\n",
    "                # print(\"+++++\")\n",
    "                for entity_relation in entities_relations:\n",
    "                    # print(entity_relation)\n",
    "                    if rel_snowball == False:\n",
    "                        score, snowball_pos_pattern = check_pos_pattern_and_update(snowball_pos_pattern, entity_relation[2][1], total_index, re_compute)\n",
    "                    else:\n",
    "                        filter_rel_types = filter_valid_rel_type(snowball_pos_ent_type, entity_relation[1][2])\n",
    "                        score, rel_type, snowball_pos_pattern_filter_rel = check_rel_pos_pattern_and_update(snowball_pos_pattern, entity_relation[2][1], filter_rel_types, total_index, re_compute)\n",
    "                    # print(\"POS Pattern Score: \", score)\n",
    "                    if score != False:\n",
    "                        valid_ents.append([entity_relation[0][0], entity_relation[0][1]])\n",
    "                        valid_ents_typ.append(entity_relation[1][2])\n",
    "                        valid_relationships.append(entity_relation[2][0])\n",
    "                        valid_pos.append(entity_relation[2][1])\n",
    "                        valid_ids.append(entity_relation[1])\n",
    "                        if rel_snowball == True:\n",
    "                            valid_rel.append(rel_type)\n",
    "                            \n",
    "                # print(\"=====\")\n",
    "            \n",
    "\n",
    "            if \"span\" in ground_truth:\n",
    "                true_positives, false_positives, false_negatives, pred_grd_rel_type = benchmark(valid_relationships, valid_ids, valid_rel, ground_truth[[\"rel type\", \"entity 1 mention ID\", \"entity 2 mention ID\", \"pos_pattern\", \"span\"]], rel_type_out)\n",
    "\n",
    "                print(\"\\n\")\n",
    "                print(\"BENCHMARK:\")\n",
    "                print(len(pred_grd_rel_type))\n",
    "\n",
    "                print(\"True Positives: %d\" % true_positives)\n",
    "                print(\"False Positives: %d\" % false_positives)\n",
    "                print(\"False Negatives: %d\" % false_negatives)\n",
    "\n",
    "                print(\"\\n\")\n",
    "                \n",
    "                all_valid_relationships.append(valid_relationships)\n",
    "                all_valid_pos.append(valid_pos)\n",
    "                all_valid_rel.append(valid_rel)\n",
    "                all_valid_ents.append(valid_ents)\n",
    "                all_valid_ents_type.append(valid_ents_typ)\n",
    "                all_pred_grd_rel_type.append(pred_grd_rel_type)\n",
    "\n",
    "                if((true_positives + false_positives) != 0):\n",
    "                    all_precision.append(precision(true_positives, false_positives))\n",
    "                else:\n",
    "                     all_precision.append(0)\n",
    "\n",
    "                if((true_positives + false_negatives) != 0):\n",
    "                    all_recall.append(recall(true_positives, false_negatives))\n",
    "                else:\n",
    "                    all_recall.append(0)\n",
    "                    \n",
    "            else:\n",
    "                print(\"\\nCan't benchmark ground truth file empty\")\n",
    "\n",
    "\n",
    "            print(\"==================End of File==================\")\n",
    "\n",
    "            print(\"\\n\")\n",
    "        \n",
    "        except EmptyDataError:\n",
    "            print(\"One of the csv file is empty\")\n",
    "        \n",
    "    if(len(all_precision) > 0 and len(all_recall) > 0):\n",
    "        \n",
    "        print(\"==================Final Result==================\")\n",
    "\n",
    "        print(\"\\n\")\n",
    "\n",
    "        print(\"Average Precision %f\" %np.mean(all_precision))\n",
    "        print(\"Average Recall %f\" %np.mean(all_recall))\n",
    "        \n",
    "        return all_precision, all_recall, all_valid_relationships, all_valid_pos, all_valid_rel, all_valid_ents, all_valid_ents_type, all_pred_grd_rel_type\n",
    "\n",
    "        print(\"\\n\")\n",
    "        \n",
    "        print(\"===============================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434100fa-e418-4cf1-939a-0c0aab0181e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\"File Name\", \"Precision\", \"Recall\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f68c10-a4a9-4d3d-bc26-58299864727c",
   "metadata": {
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "# Benchmarking ACE2004 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffff2a8f-4232-4278-9b3b-b971e061131e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged_token_files_2004 = glob.glob(\"../Data/relex_processed_data/relex/ACE2004/tagged_tokens/*\")\n",
    "ground_truth_files_2004 = glob.glob(\"../Data/relex_processed_data/relex/ACE2004/ground_truth/*\")\n",
    "raw_text_files_2004 = glob.glob(\"../Data/relex_processed_data/relex/ACE2004/raw_text/*\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c2b704e-e439-4621-af9d-778018f06d64",
   "metadata": {},
   "source": [
    "## 70% Sampling of all files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b39a955-cd5d-4721-b876-3c098c438159",
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged_token_files_2004_sample = tagged_token_files_2004[:int(len(tagged_token_files_2004) * .70)]\n",
    "ground_truth_files_2004_sample = ground_truth_files_2004[:int(len(ground_truth_files_2004) * .70)]\n",
    "raw_text_files_2004_sample = raw_text_files_2004[:int(len(raw_text_files_2004) * .70)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc9b4930-d559-48d8-a06d-4102076a0c1f",
   "metadata": {},
   "source": [
    "## 30% Sampling of all files for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac48af9-200c-481c-a004-4f8ae767d988",
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged_token_files_2004_sample_test = tagged_token_files_2004[int(len(tagged_token_files_2004) * .70):]\n",
    "ground_truth_files_2004_sample_test = ground_truth_files_2004[int(len(ground_truth_files_2004) * .70):]\n",
    "raw_text_files_2004_sample_test = raw_text_files_2004[int(len(raw_text_files_2004) * .70):]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6544e7f5-bfd5-4df0-9e64-458814cb555d",
   "metadata": {},
   "source": [
    "## 70% sampled SnowBall from ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bfb0f11-c0a3-478c-9536-bd7658ecdaae",
   "metadata": {},
   "outputs": [],
   "source": [
    "ACE2004_file_dir_files = glob.glob(\"../Data/relex_processed_data/relex/ACE2004/ground_truth/*.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0663bf91-bea5-41cd-a8eb-7cdae99788fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "ACE2004_file_dir_files_sample = ACE2004_file_dir_files[:int(len(ACE2004_file_dir_files) * .70)]\n",
    "snowball_index_2004 = generate_snowball(ACE2004_file_dir_files_sample)\n",
    "snowball_pos_pattern_2004, ACE2004_total_index = cal_rank(snowball_index_2004)\n",
    "snowball_pos_pattern_2004 = sort_dict(snowball_pos_pattern_2004)\n",
    "snowball_pos_pattern_2004_filter = remove_out(snowball_pos_pattern_2004)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b8b3f1-df8f-4931-ad66-14515fc87e32",
   "metadata": {},
   "source": [
    "## 70% sampled SnowBall with relations types from ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d9b924-d32c-4b57-8bef-81077b95a193",
   "metadata": {},
   "outputs": [],
   "source": [
    "ACE2004_file_dir_files_sample = ACE2004_file_dir_files[:int(len(ACE2004_file_dir_files) * .70)]\n",
    "snowball_index_rel_2004, snowball_pos_ent_type_2004, rel_type_out_2004, list_empty_ct, sum_ct = generate_rel_snowball(ACE2004_file_dir_files_sample, 10)\n",
    "\n",
    "print(sum(sum_ct))\n",
    "print(\"\\nMissing ground truth for %d\" %(sum(list_empty_ct)))\n",
    "ACE2004_total_index_rel = {}\n",
    "snowball_pos_pattern_2004_filter_rel = {}\n",
    "\n",
    "for key, value in snowball_index_rel_2004.items():\n",
    "    snowball_pos_pattern, ACE2004_total_index_rel[key] = cal_rank(value)\n",
    "    snowball_pos_pattern = sort_dict(snowball_pos_pattern)\n",
    "    snowball_pos_pattern_2004_filter_rel[key] = remove_out(snowball_pos_pattern)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "688ab53c-4d9e-4c51-a0dd-04e8421dd22a",
   "metadata": {},
   "source": [
    "## Benchmarking on Trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c3f6e4-200e-4b71-a5c2-b442671f4711",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_precision_2004, all_recall_2004 = benchmark_dataset(tagged_token_files_2004_sample, ground_truth_files_2004_sample, raw_text_files_2004_sample, snowball_pos_pattern_2004_filter, ACE2004_total_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19b94799-d923-4faa-92d2-800ee332e686",
   "metadata": {},
   "source": [
    "## Benchmarking on Trained - Rel Snowball"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "605a05db-cbe9-4805-85eb-d5c44eea8cb4",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_precision_rel_2004, all_recall_rel_2004, all_valid_relationships, all_valid_pos, all_valid_rel, all_valid_ents, all_valid_ents_type, all_pred_grd_rel_type = benchmark_dataset(tagged_token_files_2004_sample, ground_truth_files_2004_sample, raw_text_files_2004_sample, snowball_pos_pattern_2004_filter_rel, ACE2004_total_index_rel, snowball_pos_ent_type_2004, rel_type_out_2004, False, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "255bfe51-38dc-4aad-8777-448ea5f9b58d",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('Predicted Rel Type , Actual Rel Type , Correct Prediction , Entity 1 , Entity 2 , Entity 1 type , Entity 2 type , Text Span , Text POS')\n",
    "for index1, doc_enitites in enumerate(all_valid_ents):\n",
    "    for index2, entities in enumerate(doc_enitites):\n",
    "        # tmp1 = tmp2 = 'test'\n",
    "        tmp1, tmp2 = all_pred_grd_rel_type[index1][index2]\n",
    "        if tmp1==tmp2:\n",
    "            correct = True\n",
    "        else:\n",
    "            correct = False\n",
    "        print(tmp1, ',', tmp2, ',', correct, ',', entities[0], ',', entities[1], ',', all_valid_ents_type[index1][index2].split('-')[0], ',', all_valid_ents_type[index1][index2].split('-')[1], ',', all_valid_relationships[index1][index2], ',', all_valid_pos[index1][index2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b2ff6b2-fad7-493e-8fd9-b7cc24196f93",
   "metadata": {},
   "source": [
    "## Benchmarking on Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "369f0d9f-3a79-49d0-a2c7-462b7e692e33",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_precision_2004_test, all_recall_2004_test = benchmark_dataset(tagged_token_files_2004_sample_test, ground_truth_files_2004_sample_test, raw_text_files_2004_sample_test, snowball_pos_pattern_2004_filter, ACE2004_total_index, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b825e471-af35-4fa0-a388-ed832e7a0e32",
   "metadata": {},
   "source": [
    "## Benchmarking on Test - Rel Snowball"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b79c5a-3f7f-4c6b-8ea6-eff61630dc59",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_precision_rel_2004_test, all_recall_rel_2004_test, all_valid_relationships, all_valid_pos, all_valid_rel, all_valid_ents, all_valid_ents_type, all_pred_grd_rel_type = benchmark_dataset(tagged_token_files_2004_sample_test, ground_truth_files_2004_sample_test, raw_text_files_2004_sample_test, snowball_pos_pattern_2004_filter_rel, ACE2004_total_index_rel, snowball_pos_ent_type_2004, rel_type_out_2004, True, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100d4783-50f4-4c5e-9ae9-4c5cae2092b3",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# print('Predicted Rel Type , Actual Rel Type , Correct Prediction , Entity 1 , Entity 2 , Entity 1 type , Entity 2 type , Text Span , Text POS')\n",
    "for index1, doc_enitites in enumerate(all_valid_ents):\n",
    "    for index2, entities in enumerate(doc_enitites):\n",
    "        # tmp1 = tmp2 = 'test'\n",
    "        tmp1, tmp2 = all_pred_grd_rel_type[index1][index2]\n",
    "        if tmp1==tmp2:\n",
    "            correct = True\n",
    "        else:\n",
    "            correct = False\n",
    "        print(tmp1, ',', tmp2, ',', correct, ',', entities[0], ',', entities[1], ',', all_valid_ents_type[index1][index2].split('-')[0], ',', all_valid_ents_type[index1][index2].split('-')[1], ',', all_valid_relationships[index1][index2], ',', all_valid_pos[index1][index2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bc22e78-0aa2-46ae-8ab1-bfaadd8be226",
   "metadata": {},
   "source": [
    "## Making result dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7152980-df33-4908-b425-8b8521314825",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ACE2004_sample_result = pd.DataFrame(data=[[x.split('/')[-1].split(\"\\\\\")[-1] for x in raw_text_files_2004_sample], all_precision_rel_2004, all_recall_rel_2004]).T\n",
    "ACE2004_sample_result.columns = columns\n",
    "\n",
    "ACE2004_test_result = pd.DataFrame(data=[[x.split('/')[-1].split(\"\\\\\")[-1] for x in raw_text_files_2004_sample_test], all_precision_rel_2004_test, all_recall_rel_2004_test]).T\n",
    "ACE2004_test_result.columns = columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c2f3d9-48c1-4d64-ac84-5fc09424f07e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ACE2004_results = pd.ExcelWriter('Rel_Type/ACE2004_rel_results.xlsx', engine='xlsxwriter') \n",
    "\n",
    "ACE2004_sample_result.to_excel(ACE2004_results, sheet_name='Sample', index=False)\n",
    "ACE2004_test_result.to_excel(ACE2004_results, sheet_name='Test', index=False)\n",
    "\n",
    "ACE2004_results.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd08abab-cfa9-4253-b969-e268d6890924",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "# Benchmarking ACE2005 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ad376e-10de-4026-af2a-ec1170853d8f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tagged_token_files_2005 = glob.glob(\"../Data/relex_processed_data/relex/ACE2005/tagged_tokens/*\")\n",
    "ground_truth_files_2005 = glob.glob(\"../Data/relex_processed_data/relex/ACE2005/ground_truth/*\")\n",
    "raw_text_files_2005 = glob.glob(\"../Data/relex_processed_data/relex/ACE2005/raw_text/*\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc7d015c-07be-4f75-b054-e5f22494615a",
   "metadata": {},
   "source": [
    "## 70% Sampling of all files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75550fa6-7160-4c9d-9cc9-266e20a8fdb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged_token_files_2005_sample = tagged_token_files_2005[:int(len(tagged_token_files_2005) * .70)]\n",
    "ground_truth_files_2005_sample = ground_truth_files_2005[:int(len(ground_truth_files_2005) * .70)]\n",
    "raw_text_files_2005_sample = raw_text_files_2005[:int(len(raw_text_files_2005) * .70)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fac2c691-6729-42df-bf2e-4dbd0126df4e",
   "metadata": {},
   "source": [
    "## 30% Sampling of all files for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "479cf6d1-f6e6-44be-aa78-7a307cdee340",
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged_token_files_2005_sample_test = tagged_token_files_2005[int(len(tagged_token_files_2005) * .70):]\n",
    "ground_truth_files_2005_sample_test = ground_truth_files_2005[int(len(ground_truth_files_2005) * .70):]\n",
    "raw_text_files_2005_sample_test = raw_text_files_2005[int(len(raw_text_files_2005) * .70):]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff114ed-3740-4388-883b-a42c792ca1f0",
   "metadata": {},
   "source": [
    "## 70% sampled SnowBall from ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a8bab1-f408-4109-b155-4716980d7fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ACE2005_file_dir_files = glob.glob(\"../Data/relex_processed_data/relex/ACE2005/ground_truth/*.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd6d80fd-8327-4481-8a47-930fff4f7e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "ACE2005_file_dir_files_sample = ACE2005_file_dir_files[:int(len(ACE2005_file_dir_files) * .70)]\n",
    "snowball_index_2005 = generate_snowball(ACE2005_file_dir_files_sample)\n",
    "snowball_pos_pattern_2005, ACE2005_total_index = cal_rank(snowball_index_2005)\n",
    "snowball_pos_pattern_2005 = sort_dict(snowball_pos_pattern_2005)\n",
    "snowball_pos_pattern_2005_filter = remove_out(snowball_pos_pattern_2005)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f48631b0-0acd-4e99-9ca3-243b349a735a",
   "metadata": {},
   "source": [
    "## 70% sampled SnowBall with relations types from ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c84b365-6224-48ab-9d66-4dc7668e4770",
   "metadata": {},
   "outputs": [],
   "source": [
    "ACE2005_file_dir_files_sample = ACE2005_file_dir_files[:int(len(ACE2005_file_dir_files) * .70)]\n",
    "snowball_index_rel_2005, snowball_pos_ent_type_2005, rel_type_out_2005, cmpt_cp, sum_ct = generate_rel_snowball(ACE2005_file_dir_files_sample, 20)\n",
    "\n",
    "print(sum(sum_ct))\n",
    "print(\"\\n Missing pos pattern %d\" %(sum(cmpt_cp)))\n",
    "ACE2005_total_index_rel = {}\n",
    "snowball_pos_pattern_2005_filter_rel = {}\n",
    "\n",
    "for key, value in snowball_index_rel_2005.items():\n",
    "    snowball_pos_pattern, ACE2005_total_index_rel[key] = cal_rank(value)\n",
    "    snowball_pos_pattern = sort_dict(snowball_pos_pattern)\n",
    "    snowball_pos_pattern_2005_filter_rel[key] = remove_out(snowball_pos_pattern)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41f303bd-bb37-44c3-9137-30b342cbc6b3",
   "metadata": {},
   "source": [
    "## Benchmarking on Trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6030903-6534-4fa6-b318-1ae06acf1895",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_precision_2005, all_recall_2005 = benchmark_dataset(tagged_token_files_2005_sample, ground_truth_files_2005_sample, raw_text_files_2005_sample, snowball_pos_pattern_2005_filter, ACE2005_total_index, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4221b292-b86c-4faa-9a8b-aac87517a0b7",
   "metadata": {},
   "source": [
    "## Benchmarking on Trained - Rel Snowball"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06dea079-1afd-4feb-ad70-dd02b9d5b5c2",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_precision_rel_2005, all_recall_rel_2005, all_valid_relationships, all_valid_pos, all_valid_rel, all_valid_ents, all_valid_ents_type, all_pred_grd_rel_type = benchmark_dataset(tagged_token_files_2005_sample, ground_truth_files_2005_sample, raw_text_files_2005_sample, snowball_pos_pattern_2005_filter_rel, ACE2005_total_index_rel, snowball_pos_ent_type_2005, rel_type_out_2005, False, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9cb8e4c-a547-41dd-ab84-45b11389d171",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('Predicted Rel Type , Actual Rel Type , Correct Prediction , Entity 1 , Entity 2 , Entity 1 type , Entity 2 type , Text Span , Text POS')\n",
    "for index1, doc_enitites in enumerate(all_valid_ents):\n",
    "    for index2, entities in enumerate(doc_enitites):\n",
    "        # tmp1 = tmp2 = 'test'\n",
    "        tmp1, tmp2 = all_pred_grd_rel_type[index1][index2]\n",
    "        if tmp1==tmp2:\n",
    "            correct = True\n",
    "        else:\n",
    "            correct = False\n",
    "        print(tmp1, ',', tmp2, ',', correct, ',', entities[0], ',', entities[1], ',', all_valid_ents_type[index1][index2].split('-')[0], ',', all_valid_ents_type[index1][index2].split('-')[1], ',', all_valid_relationships[index1][index2], ',', all_valid_pos[index1][index2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9fe5640-708a-4b62-89a2-3d9a7cf34493",
   "metadata": {},
   "source": [
    "## Benchmarking on Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55fdb2fb-dd0f-41a7-8279-511a3ca9c2ab",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_precision_2005_test, all_recall_2005_test = benchmark_dataset(tagged_token_files_2005_sample_test, ground_truth_files_2005_sample_test, raw_text_files_2005_sample_test, snowball_pos_pattern_2005_filter, ACE2005_total_index, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c70a3470-660e-43e4-9217-bcdf024cafe1",
   "metadata": {},
   "source": [
    "## Benchmarking on Test - Rel Snowball"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d72f2d57-92a5-4687-93db-e21aaebacc32",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_precision_rel_2005_test, all_recall_rel_2005_test, all_valid_relationships, all_valid_pos, all_valid_rel, all_valid_ents, all_valid_ents_type, all_pred_grd_rel_type = benchmark_dataset(tagged_token_files_2005_sample_test, ground_truth_files_2005_sample_test, raw_text_files_2005_sample_test, snowball_pos_pattern_2005_filter_rel, ACE2005_total_index_rel, snowball_pos_ent_type_2005, rel_type_out_2005, True, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f809dbe-be21-4338-865a-56f085a2d4eb",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# print('Predicted Rel Type , Actual Rel Type , Correct Prediction , Entity 1 , Entity 2 , Entity 1 type , Entity 2 type , Text Span , Text POS')\n",
    "for index1, doc_enitites in enumerate(all_valid_ents):\n",
    "    for index2, entities in enumerate(doc_enitites):\n",
    "        # tmp1 = tmp2 = 'test'\n",
    "        tmp1, tmp2 = all_pred_grd_rel_type[index1][index2]\n",
    "        if tmp1==tmp2:\n",
    "            correct = True\n",
    "        else:\n",
    "            correct = False\n",
    "        print(tmp1, ',', tmp2, ',', correct, ',', entities[0], ',', entities[1], ',', all_valid_ents_type[index1][index2].split('-')[0], ',', all_valid_ents_type[index1][index2].split('-')[1], ',', all_valid_relationships[index1][index2], ',', all_valid_pos[index1][index2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d7cb73-5868-4db2-9d9e-189a03634727",
   "metadata": {},
   "source": [
    "## Making result dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9448811-21bd-4bdc-b633-e610217f3c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "ACE2005_sample_result = pd.DataFrame(data=[[x.split('/')[-1].split(\"\\\\\")[-1] for x in raw_text_files_2005_sample], all_precision_rel_2005, all_recall_rel_2005]).T\n",
    "ACE2005_sample_result.columns = columns\n",
    "\n",
    "ACE2005_test_result = pd.DataFrame(data=[[x.split('/')[-1].split(\"\\\\\")[-1] for x in raw_text_files_2005_sample_test], all_precision_rel_2005_test, all_recall_rel_2005_test]).T\n",
    "ACE2005_test_result.columns = columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de1e6c50-72e1-4ec0-8469-e1b8e4002622",
   "metadata": {},
   "outputs": [],
   "source": [
    "ACE2005_results = pd.ExcelWriter('Rel_Type/ACE2005_rel_results.xlsx', engine='xlsxwriter') \n",
    "\n",
    "ACE2005_sample_result.to_excel(ACE2005_results, sheet_name='Sample', index=False)\n",
    "ACE2005_test_result.to_excel(ACE2005_results, sheet_name='Test', index=False)\n",
    "\n",
    "ACE2005_results.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3adb779-7849-4e6e-bc77-1fb662fcc642",
   "metadata": {
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "# Benchmarking docred dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4322e78b-355f-4f59-93fb-c9f5e734a57d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tagged_token_files_docred = glob.glob(\"../Data/relex_processed_data/relex/docred/tagged_tokens/*\")\n",
    "ground_truth_files_docred = glob.glob(\"../Data/relex_processed_data/relex/docred/ground_truth/*\")\n",
    "raw_text_files_docred = glob.glob(\"../Data/relex_processed_data/relex/docred/raw_text/*\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a7ac13a-297b-4f14-8b98-c6e03ccd28e4",
   "metadata": {},
   "source": [
    "## 60% Sampling of all files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d3c6bb-c489-4a58-a830-06b2be4d36d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged_token_files_docred_sample = tagged_token_files_docred[:int(len(tagged_token_files_docred) * .60)]\n",
    "ground_truth_files_docred_sample = ground_truth_files_docred[:int(len(ground_truth_files_docred) * .60)]\n",
    "raw_text_files_docred_sample = raw_text_files_docred[:int(len(raw_text_files_docred) * .60)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94f4bc00-646d-4d53-b015-45d76cd29d1b",
   "metadata": {},
   "source": [
    "## 40% Sampling of all files for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453c420e-a834-486a-8b60-c9c9b6b1b653",
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged_token_files_docred_sample_test = tagged_token_files_docred[int(len(tagged_token_files_docred) * .60):]\n",
    "ground_truth_files_docred_sample_test = ground_truth_files_docred[int(len(ground_truth_files_docred) * .60):]\n",
    "raw_text_files_docred_sample_test = raw_text_files_docred[int(len(raw_text_files_docred) * .60):]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "006a1307-e455-4141-8405-c422967429bb",
   "metadata": {},
   "source": [
    "## 70% sampled SnowBall from ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "574afd3a-f937-4dff-9f24-d92b23837ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "docred_file_dir_files = glob.glob(\"../Data/relex_processed_data/relex/docred/ground_truth/*.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "181298da-36c5-41e8-bb59-b40005d51c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "docred_file_dir_files_sample = docred_file_dir_files[:int(len(docred_file_dir_files) * .70)]\n",
    "snowball_index_docred = generate_snowball(docred_file_dir_files_sample)\n",
    "snowball_pos_pattern_docred, docred_total_index  = cal_rank(snowball_index_docred)\n",
    "snowball_pos_pattern_docred = sort_dict(snowball_pos_pattern_docred)\n",
    "snowball_pos_pattern_docred_filter = remove_out(snowball_pos_pattern_docred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a060fe-78b7-4e48-b5ec-02b50c5235cb",
   "metadata": {},
   "source": [
    "## 70% sampled SnowBall with relations types from ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d108b696-ebec-40fa-baf5-cb4c19273d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "docred_file_dir_files_sample = docred_file_dir_files[:int(len(docred_file_dir_files) * .70)]\n",
    "snowball_index_rel_docred, snowball_pos_ent_type_docred, rel_type_out_docred, empt_ct, sum_ct = generate_rel_snowball(docred_file_dir_files_sample, 5)\n",
    "\n",
    "print(sum(sum_ct))\n",
    "print(\"\\nMissing pos pattern %d\" %(sum(empt_ct)))\n",
    "docred_total_index_rel = {}\n",
    "snowball_pos_pattern_docred_filter_rel = {}\n",
    "\n",
    "for key, value in snowball_index_rel_docred.items():\n",
    "    snowball_pos_pattern, docred_total_index_rel[key] = cal_rank(value)\n",
    "    snowball_pos_pattern = sort_dict(snowball_pos_pattern)\n",
    "    snowball_pos_pattern_docred_filter_rel[key] = remove_out(snowball_pos_pattern)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "987cd8c0-8efd-498e-be9e-118b580f73f5",
   "metadata": {},
   "source": [
    "## Benchmarking on Trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc5a163-f57e-49ce-bde0-e0154e998684",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_precision_docred, all_recall_docred = benchmark_dataset(tagged_token_files_docred_sample, ground_truth_files_docred_sample, raw_text_files_docred_sample, snowball_pos_pattern_docred_filter, docred_total_index, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e296d7-4120-4ddf-8c14-3413d9d7049b",
   "metadata": {},
   "source": [
    "## Benchmarking on Trained - Rel Snowball"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce22d7a-4cdc-4c55-a757-2bdf7b9bd1dc",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_precision_rel_docred, all_recall_rel_docred, all_valid_relationships, all_valid_pos, all_valid_rel, all_valid_ents, all_valid_ents_type, all_pred_grd_rel_type = benchmark_dataset(tagged_token_files_docred_sample, ground_truth_files_docred_sample, raw_text_files_docred_sample, snowball_pos_pattern_docred_filter_rel, docred_total_index_rel, snowball_pos_ent_type_docred, rel_type_out_docred, False, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "333c3f75-31b3-4f03-96f6-784ae6b006f9",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('Predicted Rel Type , Actual Rel Type , Correct Prediction , Entity 1 , Entity 2 , Entity 1 type , Entity 2 type , Text Span , Text POS')\n",
    "for index1, doc_enitites in enumerate(all_valid_ents):\n",
    "    for index2, entities in enumerate(doc_enitites):\n",
    "        # tmp1 = tmp2 = 'test'\n",
    "        tmp1, tmp2 = all_pred_grd_rel_type[index1][index2]\n",
    "        if tmp1==tmp2:\n",
    "            correct = True\n",
    "        else:\n",
    "            correct = False\n",
    "        print(tmp1, ',', tmp2, ',', correct, ',', entities[0], ',', entities[1], ',', all_valid_ents_type[index1][index2].split('-')[0], ',', all_valid_ents_type[index1][index2].split('-')[1], ',', all_valid_relationships[index1][index2], ',', all_valid_pos[index1][index2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84f71aa6-7892-4bc1-9897-5c1d64875187",
   "metadata": {},
   "source": [
    "## Benchmarking on Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc63b572-e9f6-41f4-9604-900f133f54fc",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_precision_docred_test, all_recall_docred_test = benchmark_dataset(tagged_token_files_docred_sample_test, ground_truth_files_docred_sample_test, raw_text_files_docred_sample_test, snowball_pos_pattern_docred_filter, docred_total_index, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2eddb2a-ae06-46ca-8031-a33c7d5075a5",
   "metadata": {},
   "source": [
    "## Benchmarking on Test - Rel Snowball"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d09e31-0996-4402-be2f-4298f628f1fc",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_precision_rel_docred_test, all_recall_rel_docred_test, all_valid_relationships, all_valid_pos, all_valid_rel, all_valid_ents, all_valid_ents_type, all_pred_grd_rel_type = benchmark_dataset(tagged_token_files_docred_sample_test, ground_truth_files_docred_sample_test, raw_text_files_docred_sample_test, snowball_pos_pattern_docred_filter_rel, docred_total_index_rel, snowball_pos_ent_type_docred, rel_type_out_docred, True, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb48f67-db2d-4eed-8b92-1af915ce5622",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# print('Predicted Rel Type , Actual Rel Type , Correct Prediction , Entity 1 , Entity 2 , Entity 1 type , Entity 2 type , Text Span , Text POS')\n",
    "for index1, doc_enitites in enumerate(all_valid_ents):\n",
    "    for index2, entities in enumerate(doc_enitites):\n",
    "        # tmp1 = tmp2 = 'test'\n",
    "        tmp1, tmp2 = all_pred_grd_rel_type[index1][index2]\n",
    "        if tmp1==tmp2:\n",
    "            correct = True\n",
    "        else:\n",
    "            correct = False\n",
    "        print(tmp1, ',', tmp2, ',', correct, ',', entities[0], ',', entities[1], ',', all_valid_ents_type[index1][index2].split('-')[0], ',', all_valid_ents_type[index1][index2].split('-')[1], ',', all_valid_relationships[index1][index2], ',', all_valid_pos[index1][index2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf530727-84e1-4e0c-94e6-9f50256776f6",
   "metadata": {},
   "source": [
    "## Making result dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df77f6dc-f6c3-457e-9dda-cc5d14e46396",
   "metadata": {},
   "outputs": [],
   "source": [
    "docred_sample_result = pd.DataFrame(data=[[x.split('/')[-1].split(\"\\\\\")[-1] for x in raw_text_files_docred_sample], all_precision_rel_docred, all_recall_rel_docred]).T\n",
    "docred_sample_result.columns = columns\n",
    "\n",
    "docred_test_result = pd.DataFrame(data=[[x.split('/')[-1].split(\"\\\\\")[-1] for x in raw_text_files_docred_sample_test], all_precision_rel_docred_test, all_recall_rel_docred_test]).T\n",
    "docred_test_result.columns = columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "668edff8-698f-4b34-b4a7-a81d1706c589",
   "metadata": {},
   "outputs": [],
   "source": [
    "docred_results = pd.ExcelWriter('Rel_Type/docred_rel_results.xlsx', engine='xlsxwriter') \n",
    "\n",
    "docred_sample_result.to_excel(docred_results, sheet_name='Sample', index=False)\n",
    "docred_test_result.to_excel(docred_results, sheet_name='Test', index=False)\n",
    "\n",
    "docred_results.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c68567c0-2745-443d-9b6f-1a782cae800f",
   "metadata": {
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "# Benchmarking re3d dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c46b35-0c8f-4c97-8d44-7e844aa835cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tagged_token_files_re3d = glob.glob(\"../Data/relex_processed_data/relex/re3d/tagged_tokens/*\")\n",
    "ground_truth_files_re3d = glob.glob(\"../Data/relex_processed_data/relex/re3d/ground_truth/*\")\n",
    "raw_text_files_re3d = glob.glob(\"../Data/relex_processed_data/relex/re3d/raw_text/*\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "789c8096-7d6a-42d1-9a9b-51df8dec09b6",
   "metadata": {},
   "source": [
    "## 70% Sampling of all files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e974a6e2-0b50-4644-9ba6-2cfc48e7dce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged_token_files_re3d_sample = tagged_token_files_re3d[:int(len(tagged_token_files_re3d) * .70)]\n",
    "ground_truth_files_re3d_sample = ground_truth_files_re3d[:int(len(ground_truth_files_re3d) * .70)]\n",
    "raw_text_files_re3d_sample = raw_text_files_re3d[:int(len(raw_text_files_re3d) * .70)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45f1aab8-8c9b-4b0e-841d-56ee0178ed3a",
   "metadata": {},
   "source": [
    "## 30% Sampling of all files for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a69f403-4efe-4944-a07c-eabf84e7c2bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged_token_files_re3d_sample_test = tagged_token_files_re3d[int(len(tagged_token_files_re3d) * .70):]\n",
    "ground_truth_files_re3d_sample_test = ground_truth_files_re3d[int(len(ground_truth_files_re3d) * .70):]\n",
    "raw_text_files_re3d_sample_test = raw_text_files_re3d[int(len(raw_text_files_re3d) * .70):]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bafe5f66-695f-4f8d-b4b2-2c9448280da2",
   "metadata": {},
   "source": [
    "## 70% sampled SnowBall from ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb9ce34a-deb4-4b53-a2cc-410cc2a9671c",
   "metadata": {},
   "outputs": [],
   "source": [
    "re3d_file_dir_files = glob.glob(\"../Data/relex_processed_data/relex/re3d/ground_truth/*.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9391063-0e7e-44f6-b680-88b8b6d92f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "re3d_file_dir_files_sample = re3d_file_dir_files[:int(len(re3d_file_dir_files) * .70)]\n",
    "snowball_index_re3d = generate_snowball(re3d_file_dir_files_sample)\n",
    "snowball_pos_pattern_re3d, re3d_total_index = cal_rank(snowball_index_re3d)\n",
    "snowball_pos_pattern_re3d = sort_dict(snowball_pos_pattern_re3d)\n",
    "snowball_pos_pattern_re3d_filter = remove_out(snowball_pos_pattern_re3d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d27371a7-467f-4529-b3e8-b63dff67e742",
   "metadata": {},
   "source": [
    "## 70% sampled SnowBall with relations types from ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1deb1454-978a-4ac7-b7f3-3ac6acbecb9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "re3d_file_dir_files_sample = re3d_file_dir_files[:int(len(re3d_file_dir_files) * .70)]\n",
    "snowball_index_rel_re3d, snowball_pos_ent_type_re3d, rel_type_out_re3d, emp_ct = generate_rel_snowball(re3d_file_dir_files_sample, 10)\n",
    "\n",
    "print(\"\\nMissing pos pattern %d\" %(sum(emp_ct)))\n",
    "re3d_total_index_rel = {}\n",
    "snowball_pos_pattern_re3d_filter_rel = {}\n",
    "\n",
    "for key, value in snowball_index_rel_re3d.items():\n",
    "    snowball_pos_pattern, re3d_total_index_rel[key] = cal_rank(value)\n",
    "    snowball_pos_pattern = sort_dict(snowball_pos_pattern)\n",
    "    snowball_pos_pattern_re3d_filter_rel[key] = remove_out(snowball_pos_pattern)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e78ac1e2-6417-4532-90af-aad4d07efdb8",
   "metadata": {},
   "source": [
    "## Benchmarking on Trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fcbb7d8-0066-4080-b606-2d9145c813d0",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_precision_re3d, all_recall_re3d = benchmark_dataset(tagged_token_files_re3d_sample, ground_truth_files_re3d_sample, raw_text_files_re3d_sample, snowball_pos_pattern_re3d_filter, re3d_total_index, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "448ec970-2a52-45ca-8a65-5a892d50f48c",
   "metadata": {},
   "source": [
    "## Benchmarking on Trained - Rel Snowball"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "055ba01e-ebdd-4401-a343-12eaa7651547",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_precision_rel_re3d, all_recall_rel_re3d, all_valid_relationships, all_valid_pos, all_valid_rel, all_valid_ents, all_valid_ents_type, all_pred_grd_rel_type = benchmark_dataset(tagged_token_files_re3d_sample, ground_truth_files_re3d_sample, raw_text_files_re3d_sample, snowball_pos_pattern_re3d_filter_rel, re3d_total_index_rel, snowball_pos_ent_type_re3d, rel_type_out_re3d, False, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f03dd217-e69c-4ef6-bbde-6c3f1037c2c5",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('Predicted Rel Type , Actual Rel Type , Correct Prediction , Entity 1 , Entity 2 , Entity 1 type , Entity 2 type , Text Span , Text POS')\n",
    "for index1, doc_enitites in enumerate(all_valid_ents):\n",
    "    for index2, entities in enumerate(doc_enitites):\n",
    "        # tmp1 = tmp2 = 'test'\n",
    "        tmp1, tmp2 = all_pred_grd_rel_type[index1][index2]\n",
    "        if tmp1==tmp2:\n",
    "            correct = True\n",
    "        else:\n",
    "            correct = False\n",
    "        print(tmp1, ',', tmp2, ',', correct, ',', entities[0], ',', entities[1], ',', all_valid_ents_type[index1][index2].split('-')[0], ',', all_valid_ents_type[index1][index2].split('-')[1], ',', all_valid_relationships[index1][index2], ',', all_valid_pos[index1][index2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de189ca1-dc3c-4a0e-8b91-5ed868bb7b3a",
   "metadata": {},
   "source": [
    "## Benchmarking on Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35088bf4-fed8-4277-9d9f-08209dd0c2ca",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_precision_re3d_test, all_recall_re3d_test = benchmark_dataset(tagged_token_files_re3d_sample_test, ground_truth_files_re3d_sample_test, raw_text_files_re3d_sample_test, snowball_pos_pattern_re3d_filter, re3d_total_index, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d316f3a0-2fcd-44f5-9230-f4889aa28dd5",
   "metadata": {},
   "source": [
    "## Benchmarking on Test - Rel Snowball"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f460fa-4568-4506-9c82-f0dab6c66f37",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_precision_rel_re3d_test, all_recall_rel_re3d_test, all_valid_relationships, all_valid_pos, all_valid_rel, all_valid_ents, all_valid_ents_type, all_pred_grd_rel_type = benchmark_dataset(tagged_token_files_re3d_sample_test, ground_truth_files_re3d_sample_test, raw_text_files_re3d_sample_test, snowball_pos_pattern_re3d_filter_rel, re3d_total_index_rel, snowball_pos_ent_type_re3d, rel_type_out_re3d, True, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cfab530-8a65-4b45-abe4-193a01fd7ef4",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# print('Predicted Rel Type , Actual Rel Type , Correct Prediction , Entity 1 , Entity 2 , Entity 1 type , Entity 2 type , Text Span , Text POS')\n",
    "for index1, doc_enitites in enumerate(all_valid_ents):\n",
    "    for index2, entities in enumerate(doc_enitites):\n",
    "        # tmp1 = tmp2 = 'test'\n",
    "        tmp1, tmp2 = all_pred_grd_rel_type[index1][index2]\n",
    "        if tmp1==tmp2:\n",
    "            correct = True\n",
    "        else:\n",
    "            correct = False\n",
    "        print(tmp1, ',', tmp2, ',', correct, ',', entities[0], ',', entities[1], ',', all_valid_ents_type[index1][index2].split('-')[0], ',', all_valid_ents_type[index1][index2].split('-')[1], ',', all_valid_relationships[index1][index2], ',', all_valid_pos[index1][index2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "921e72c8-ba97-4fcb-8cde-d8d0859eab8b",
   "metadata": {},
   "source": [
    "## Making result dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38211da1-df7f-4d7b-8f42-94b4a9ab2844",
   "metadata": {},
   "outputs": [],
   "source": [
    "re3d_sample_result = pd.DataFrame(data=[[x.split('/')[-1].split(\"\\\\\")[-1] for x in raw_text_files_re3d_sample], all_precision_rel_re3d, all_recall_rel_re3d]).T\n",
    "re3d_sample_result.columns = columns\n",
    "\n",
    "re3d_test_result = pd.DataFrame(data=[[x.split('/')[-1].split(\"\\\\\")[-1] for x in raw_text_files_re3d_sample_test], all_precision_rel_re3d_test, all_recall_rel_re3d_test]).T\n",
    "re3d_test_result.columns = columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6941499e-4fe4-46ed-8857-0fd0c12e5cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "re3d_results = pd.ExcelWriter('REl_Type/re3d_rel_results.xlsx', engine='xlsxwriter') \n",
    "\n",
    "re3d_sample_result.to_excel(re3d_results, sheet_name='Sample', index=False)\n",
    "re3d_test_result.to_excel(re3d_results, sheet_name='Test', index=False)\n",
    "\n",
    "re3d_results.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e33700b-2437-42a3-8525-fd3a8b0c3c01",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
